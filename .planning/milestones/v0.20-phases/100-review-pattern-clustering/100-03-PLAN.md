---
phase: 100-review-pattern-clustering
plan: 03
type: tdd
wave: 2
depends_on: [01, 02]
files_modified:
  - src/knowledge/cluster-pipeline.ts
  - src/knowledge/cluster-pipeline.test.ts
autonomous: true
requirements: [CLST-01, CLST-02, CLST-04, CLST-05]

must_haves:
  truths:
    - Pipeline fetches 6-month review comment embeddings, reduces with UMAP, clusters with HDBSCAN
    - Cluster labels auto-generated from 3-5 representative samples via LLM task router
    - Labels only regenerated when cluster membership changes by >20%
    - Incremental merge assigns new embeddings to existing clusters before discovering new ones
    - Results persisted to cluster store
  artifacts:
    - src/knowledge/cluster-pipeline.ts
    - src/knowledge/cluster-pipeline.test.ts
  key_links:
    - cluster-pipeline.ts imports hdbscan from hdbscan.ts
    - cluster-pipeline.ts imports ClusterStore from cluster-store.ts
    - cluster-pipeline.ts uses TASK_TYPES.CLUSTER_LABEL via generateWithFallback
    - cluster-pipeline.ts uses umap-js for dimensionality reduction
---

<objective>
Implement the full clustering pipeline: fetch embeddings, UMAP reduce, HDBSCAN cluster, LLM label, persist.

Purpose: Core engine that discovers and labels review patterns from historical comments.
Output: Pipeline module with comprehensive TDD tests.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/references/tdd.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/phases/100-review-pattern-clustering/100-RESEARCH.md
@.planning/phases/100-review-pattern-clustering/100-01-SUMMARY.md
@.planning/phases/100-review-pattern-clustering/100-02-SUMMARY.md

<interfaces>
From src/knowledge/hdbscan.ts (plan 01):
```typescript
export function hdbscan(data: number[][], opts: HdbscanOptions): HdbscanResult;
```

From src/knowledge/cluster-types.ts (plan 01):
```typescript
export type ReviewCluster = { id: number; repo: string; slug: string; label: string; centroid: Float32Array; memberCount: number; memberCountAtLabel: number; filePaths: string[]; /* ... */ };
export type ClusterStore = { upsertCluster(...); getActiveClusters(repo); updateClusterLabel(...); writeAssignments(...); clearAssignments(...); getRunState(); saveRunState(...); };
export type ClusterRunState = { lastRunAt: Date | null; status: string; /* ... */ };
```

From src/knowledge/cluster-store.ts (plan 02):
```typescript
export function createClusterStore(opts: { sql: Sql; logger: Logger }): ClusterStore;
```

From src/llm/task-types.ts:
```typescript
export const TASK_TYPES = {
  CLUSTER_LABEL: "cluster.label",
  // ...
};
```

From src/llm/generate.ts:
```typescript
export async function generateWithFallback(opts: {
  taskType: string; resolved: ResolvedModel; prompt: string;
  system?: string; logger: Logger; repo?: string;
}): Promise<GenerateResult>;
```

From src/llm/task-router.ts:
```typescript
export interface TaskRouter { resolve(taskType: string): ResolvedModel; }
```

From umap-js (npm):
```typescript
import { UMAP } from "umap-js";
const umap = new UMAP({ nComponents: 15, nNeighbors: 15, minDist: 0.0 });
const reduced = umap.fit(data); // number[][]
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install umap-js dependency</name>
  <files>package.json</files>
  <action>
Install umap-js:
```bash
bun add umap-js
```

Verify it's added to package.json dependencies.
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && grep "umap-js" package.json</automated>
  </verify>
  <done>umap-js listed in package.json dependencies</done>
</task>

<task type="auto">
  <name>Task 2: Implement and test clustering pipeline (TDD)</name>
  <files>src/knowledge/cluster-pipeline.ts, src/knowledge/cluster-pipeline.test.ts</files>
  <action>
Implement the clustering pipeline using TDD (RED-GREEN-REFACTOR).

**Write tests first** in `cluster-pipeline.test.ts`:

1. **Full pipeline happy path**: Mock SQL returning 50 embeddings (use random Float32Arrays seeded for determinism), mock store, mock taskRouter. Verify: UMAP called, HDBSCAN called, labels generated, clusters persisted, run state saved as "completed".

2. **Empty embeddings**: No review comments in 6-month window -> run state saved as "completed" with 0 clusters.

3. **Below minimum**: Only 2 embeddings (below min_cluster_size=3) -> all noise, 0 clusters persisted.

4. **Label regeneration threshold**: Existing cluster with memberCountAtLabel=10, new memberCount=10 -> label NOT regenerated. memberCount=13 (30% increase) -> label regenerated.

5. **Pinned label skip**: Cluster with pinned=true -> label never regenerated regardless of membership change.

6. **Incremental merge**: Existing clusters in store + new embeddings. New embeddings close to existing cluster -> assigned to it. New embeddings far from all clusters -> accumulated and clustered separately.

7. **LLM label generation**: Verify generateWithFallback called with CLUSTER_LABEL task type, prompt includes 3-5 representative samples, system prompt requests JSON {slug, description}.

8. **Run state persistence**: On failure, run state saved with status="failed" and error message.

9. **6-month window**: Verify SQL query filters github_created_at >= NOW() - INTERVAL '6 months'.

**Then implement** `cluster-pipeline.ts`:

```typescript
export async function runClusterPipeline(opts: {
  sql: Sql;
  store: ClusterStore;
  taskRouter: TaskRouter;
  logger: Logger;
  repo: string;
  /** Override for testing; defaults to 3 */
  minClusterSize?: number;
}): Promise<ClusterRunState>
```

**Pipeline steps:**

1. **Load run state** from store, set status="running", save.

2. **Fetch embeddings**: Query review_comments WHERE repo, deleted=false, stale=false, embedding IS NOT NULL, github_created_at >= NOW() - INTERVAL '6 months'. Parse embedding from pgvector format to Float32Array. Return array of {id, embedding, filePath, chunkText}.

3. **Check threshold**: If embeddings.length < minClusterSize, save run state as completed with 0 clusters, return early.

4. **Load existing clusters**: `store.getActiveClusters(repo)`.

5. **Incremental merge** (if existing clusters exist):
   - For each new embedding, compute cosine similarity to all existing cluster centroids.
   - If max similarity > 0.5 (measured in original 1024-dim space): assign to that cluster.
   - Otherwise: add to "unassigned" pool.
   - Update member counts and centroids for clusters that gained members.
   - If unassigned pool has >= minClusterSize embeddings: proceed to step 6 with ONLY the unassigned pool.
   - If no existing clusters: proceed to step 6 with ALL embeddings.

6. **UMAP reduction**: Use UMAP with nComponents=15, nNeighbors=15, minDist=0.0, seed random with fixed seed (42) for reproducibility. `const umap = new UMAP({ nComponents: 15, nNeighbors: 15, minDist: 0.0, random: seedRandom(42) })`. Reduce the embedding pool to 15 dimensions.

   For seeded random, implement a simple LCG:
   ```typescript
   function seedRandom(seed: number): () => number {
     let s = seed;
     return () => { s = (s * 16807) % 2147483647; return (s - 1) / 2147483646; };
   }
   ```

7. **HDBSCAN clustering**: Call `hdbscan(reducedData, { minClusterSize: opts.minClusterSize ?? 3 })`.

8. **Build cluster records**: For each discovered cluster (label != -1):
   - Compute centroid as mean of member embeddings (in original 1024-dim space, NOT UMAP space).
   - Collect unique file paths from members.
   - Generate temporary slug from cluster ID (e.g., `cluster-${id}`).

9. **Generate labels**: For each new cluster:
   - Select 3-5 representative members (highest probability).
   - Call `generateWithFallback` with `TASK_TYPES.CLUSTER_LABEL`.
   - Prompt: "Given these review comments from the same code review pattern cluster, generate: 1) A short technical slug (e.g., 'null-check-missing') 2) A natural language description (e.g., 'Missing null checks on API response fields'). Return JSON: { slug: string, description: string }".
   - Parse JSON response. On parse failure, use fallback slug/label.

10. **Check label regeneration** for existing clusters:
    - If pinned=true: skip.
    - If |memberCount - memberCountAtLabel| / memberCountAtLabel > 0.2: regenerate label.
    - Otherwise: keep existing label.

11. **Persist**: Upsert clusters, write assignments, save run state as "completed".

12. **Retire stale clusters**: Any existing cluster with memberCount < 3 in the 60-day window -> set retired=true.

**Error handling**: Wrap entire pipeline in try/catch. On failure, save run state with status="failed" and error message. Log error. Do NOT throw â€” fail-open philosophy.

**Important**: Use `generateWithFallback` for LLM calls, NOT direct AI SDK calls. This ensures fallback and cost tracking.
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && bun test src/knowledge/cluster-pipeline.test.ts 2>&1 | tail -20</automated>
  </verify>
  <done>All pipeline tests pass. Pipeline correctly fetches, reduces, clusters, labels, persists, and handles edge cases (empty data, below threshold, pinned labels, incremental merge, failures).</done>
</task>

</tasks>

<verification>
- [ ] Pipeline fetches only 6-month window embeddings with proper filters
- [ ] UMAP reduces to 15 dimensions with fixed seed for reproducibility
- [ ] HDBSCAN uses minClusterSize=3 by default
- [ ] Labels generated via TASK_TYPES.CLUSTER_LABEL through generateWithFallback
- [ ] Label regeneration respects 20% threshold and pinned flag
- [ ] Incremental merge assigns to existing clusters before discovering new ones
- [ ] Cluster retirement at < 3 members in 60-day window
- [ ] Run state persisted on success and failure
- [ ] All tests pass
</verification>

<success_criteria>
- Full clustering pipeline works end-to-end with mock dependencies
- Incremental merge preserves existing clusters and discovers new ones
- LLM label generation produces two-layer labels (slug + description)
- Pipeline is fail-open (errors logged, not thrown)
</success_criteria>

<output>
After completion, create `.planning/phases/100-review-pattern-clustering/100-03-SUMMARY.md`
</output>
