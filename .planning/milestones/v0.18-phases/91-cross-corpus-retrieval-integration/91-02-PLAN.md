---
phase: 91-cross-corpus-retrieval-integration
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/knowledge/cross-corpus-rrf.ts
  - src/knowledge/cross-corpus-rrf.test.ts
  - src/knowledge/dedup.ts
  - src/knowledge/dedup.test.ts
autonomous: true
requirements: [KI-15, KI-19]

must_haves:
  truths:
    - "Ranked lists from different sources are merged via RRF with 1/(k + rank) scoring"
    - "Near-duplicate chunks across corpora are collapsed via cosine similarity threshold"
    - "Surviving deduped chunks carry alternate source annotations"
  artifacts:
    - path: "src/knowledge/cross-corpus-rrf.ts"
      provides: "Cross-corpus RRF engine merging heterogeneous source ranked lists"
      exports: ["crossCorpusRRF", "UnifiedRetrievalChunk"]
    - path: "src/knowledge/cross-corpus-rrf.test.ts"
      provides: "Unit tests for cross-corpus RRF"
    - path: "src/knowledge/dedup.ts"
      provides: "Cosine similarity deduplication for retrieval chunks"
      exports: ["deduplicateChunks"]
    - path: "src/knowledge/dedup.test.ts"
      provides: "Unit tests for deduplication"
  key_links:
    - from: "src/knowledge/cross-corpus-rrf.ts"
      to: "src/knowledge/dedup.ts"
      via: "RRF output is passed through dedup before final ranking"
      pattern: "deduplicateChunks"
---

<objective>
Build the cross-corpus Reciprocal Rank Fusion engine and cosine deduplication module.

Purpose: KI-15 requires RRF merging ranked lists from heterogeneous sources using `1/(k + rank)` scoring summed across lists. KI-19 requires near-duplicate chunks from different sources to be collapsed via cosine similarity threshold. This plan creates both as standalone, tested modules that the unified retrieval pipeline (plan 03) will consume.

Output: `crossCorpusRRF` function that merges ranked lists from code, review, and wiki corpora. `deduplicateChunks` function that collapses near-duplicates within and across corpora.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/91-cross-corpus-retrieval-integration/91-CONTEXT.md
@src/knowledge/types.ts
@src/knowledge/review-comment-retrieval.ts
@src/knowledge/wiki-retrieval.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create unified chunk type and cross-corpus RRF with TDD</name>
  <files>
    src/knowledge/cross-corpus-rrf.ts
    src/knowledge/cross-corpus-rrf.test.ts
  </files>
  <action>
**RED phase first.** Create `src/knowledge/cross-corpus-rrf.test.ts` with tests for:

1. Single source list produces RRF scores based on rank position
2. Two source lists — items in both get summed RRF scores
3. Three source lists (code + review + wiki) merge correctly
4. Empty lists handled gracefully
5. topK limit respected
6. Items sorted by total RRF score descending
7. Source labels preserved on each chunk
8. Recency boost: chunks from last 30 days get 10-20% score bonus (per CONTEXT.md decision)

Then **GREEN phase.** Create `src/knowledge/cross-corpus-rrf.ts`:

```typescript
export type SourceType = "code" | "review_comment" | "wiki";

export type UnifiedRetrievalChunk = {
  id: string;                    // unique key for dedup
  text: string;                  // chunk text content
  source: SourceType;            // which corpus
  sourceLabel: string;           // human-readable: "[code: file.ts]", "[review: PR #123]", "[wiki: Page Title]"
  sourceUrl: string | null;      // clickable link to source
  vectorDistance: number | null;  // original vector distance if available
  rrfScore: number;              // computed RRF score
  createdAt: string | null;      // for recency boost
  metadata: Record<string, unknown>;  // corpus-specific metadata
  alternateSources?: string[];   // populated by dedup: other sources with near-duplicate
};

export type RankedSourceList = {
  source: SourceType;
  items: UnifiedRetrievalChunk[];  // pre-sorted best-first
};

export function crossCorpusRRF(params: {
  sourceLists: RankedSourceList[];
  k?: number;                    // default 60
  topK?: number;                 // max results
  recencyBoostDays?: number;     // default 30
  recencyBoostFactor?: number;   // default 0.15 (15% boost for items within window)
  now?: Date;                    // for testing
}): UnifiedRetrievalChunk[]
```

Algorithm:
1. For each source list, assign RRF score per item: `1 / (k + rank)` where rank is 0-based position
2. Merge all items by `id` key — if same id appears in multiple lists, sum their RRF scores
3. Apply recency boost: for items with `createdAt` within `recencyBoostDays`, multiply RRF score by `(1 + recencyBoostFactor)`
4. Sort by rrfScore descending
5. Return topK results

Per CONTEXT.md: "Mild recency boost: recent results get a small bonus (10-20% for last 30 days), but old highly-relevant results still surface." Use 15% as default (middle of range).
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && npx vitest run src/knowledge/cross-corpus-rrf.test.ts 2>&1 | tail -20</automated>
  </verify>
  <done>crossCorpusRRF merges heterogeneous source lists via RRF with recency boost, all tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Create cosine similarity deduplication with TDD</name>
  <files>
    src/knowledge/dedup.ts
    src/knowledge/dedup.test.ts
  </files>
  <action>
**RED phase first.** Create `src/knowledge/dedup.test.ts` with tests for:

1. Identical texts detected as duplicates (similarity = 1.0)
2. Very different texts kept as separate (similarity < threshold)
3. Near-duplicate with similarity above threshold: lower-ranked chunk removed, higher-ranked survives
4. Surviving chunk gets `alternateSources` annotation from removed duplicate
5. Empty input returns empty output
6. Single item returns unchanged
7. Dedup happens within a single corpus (prevents duplicates inflating RRF contribution per CONTEXT.md)
8. Cross-corpus dedup: same chunk in wiki and review — keep highest-ranked

Then **GREEN phase.** Create `src/knowledge/dedup.ts`:

```typescript
export function deduplicateChunks(params: {
  chunks: UnifiedRetrievalChunk[];
  similarityThreshold?: number;   // default 0.90 (per CONTEXT.md Claude's discretion starting point)
  mode: "within-corpus" | "cross-corpus";  // within-corpus runs before RRF, cross-corpus after
}): UnifiedRetrievalChunk[]
```

Similarity computation: Use simple text-based Jaccard similarity on whitespace-tokenized words (no embedding needed for dedup — we already have the text). This avoids an extra embedding call. The cosine similarity threshold from CONTEXT.md refers to the conceptual threshold; Jaccard on tokens is the practical implementation.

Why Jaccard over embeddings: Dedup targets near-identical chunks (copy-paste, reformatted same content). Jaccard at 0.90 catches these without additional API calls. Semantic similarity for conceptually-similar-but-different-text is handled by RRF ranking, not dedup.

Algorithm:
1. Sort chunks by rrfScore descending (best first)
2. For each chunk, compare against all previously-kept chunks
3. If Jaccard similarity >= threshold with any kept chunk:
   - Skip this chunk
   - Add this chunk's source to the kept chunk's `alternateSources`
4. Return kept chunks in score order

Per CONTEXT.md: "When duplicates found: keep the highest-ranked chunk (pure quality wins, source type irrelevant)."
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && npx vitest run src/knowledge/dedup.test.ts 2>&1 | tail -20</automated>
  </verify>
  <done>deduplicateChunks collapses near-duplicates with configurable threshold, annotates survivors with alternate sources</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes
- `npx vitest run src/knowledge/cross-corpus-rrf.test.ts src/knowledge/dedup.test.ts` passes
- RRF uses k=60 default per user decision
- Recency boost is 15% for items within 30 days
- Dedup threshold starts at 0.90 per Claude's discretion
- Dedup annotates survivors with alternate sources
</verification>

<success_criteria>
- KI-15: RRF merges ranked lists from heterogeneous sources using 1/(k + rank) scoring
- KI-19: Near-duplicate chunks collapsed via similarity threshold with alternate source annotations
- Both modules are standalone, tested, and ready for pipeline integration in plan 03
</success_criteria>

<output>
After completion, create `.planning/phases/91-cross-corpus-retrieval-integration/91-02-SUMMARY.md`
</output>
