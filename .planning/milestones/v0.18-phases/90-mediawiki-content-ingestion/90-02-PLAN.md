---
phase: 90-mediawiki-content-ingestion
plan: 02
type: execute
wave: 2
depends_on: [90-01]
files_modified:
  - src/knowledge/wiki-backfill.ts
  - src/knowledge/wiki-backfill.test.ts
  - scripts/backfill-wiki.ts
  - src/knowledge/index.ts
  - package.json
autonomous: true
requirements: [KI-07, KI-08, KI-09]

must_haves:
  truths:
    - "All kodi.wiki pages can be fetched via MediaWiki API with proper pagination"
    - "Backfill CLI resumes from last sync state on restart (cursor-based)"
    - "Pages are fetched, HTML converted to markdown, chunked, embedded, and stored in wiki_pages table"
    - "Rate limiting prevents overloading kodi.wiki MediaWiki API"
    - "Redirect, stub, and disambiguation pages are skipped during backfill"
    - "Progress is logged with page count and timing"
  artifacts:
    - path: "src/knowledge/wiki-backfill.ts"
      provides: "Backfill engine with MediaWiki API pagination, rate limiting, and embedding pipeline"
      contains: "backfillWikiPages"
    - path: "scripts/backfill-wiki.ts"
      provides: "CLI entry point for wiki backfill with --source, --namespace, --dry-run flags"
      contains: "backfill-wiki"
    - path: "src/knowledge/index.ts"
      provides: "Updated barrel exports with wiki modules"
      contains: "WikiPageStore"
  key_links:
    - from: "src/knowledge/wiki-backfill.ts"
      to: "src/knowledge/wiki-store.ts"
      via: "Backfill writes chunks via WikiPageStore"
      pattern: "writeChunks|replacePageChunks"
    - from: "src/knowledge/wiki-backfill.ts"
      to: "src/knowledge/wiki-chunker.ts"
      via: "Pages are chunked before embedding"
      pattern: "chunkWikiPage"
    - from: "src/knowledge/wiki-backfill.ts"
      to: "src/knowledge/embeddings.ts"
      via: "Chunks are embedded via EmbeddingProvider before storage"
      pattern: "embeddingProvider|generate"
    - from: "scripts/backfill-wiki.ts"
      to: "src/knowledge/wiki-backfill.ts"
      via: "CLI invokes backfill engine"
      pattern: "backfillWikiPages"
---

<objective>
Implement the MediaWiki API backfill engine and CLI for fetching all kodi.wiki pages, converting to markdown, chunking, embedding, and storing.

Purpose: Populate the wiki_pages table with all kodi.wiki content so it becomes searchable. This is the primary data ingestion path.
Output: Backfill engine module and CLI script with resume support, rate limiting, and progress logging.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/90-mediawiki-content-ingestion/90-01-SUMMARY.md
@src/knowledge/wiki-types.ts
@src/knowledge/wiki-store.ts
@src/knowledge/wiki-chunker.ts
@src/knowledge/review-comment-backfill.ts
@scripts/backfill-review-comments.ts
@src/knowledge/embeddings.ts
@src/db/client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement MediaWiki API backfill engine</name>
  <files>src/knowledge/wiki-backfill.ts, src/knowledge/wiki-backfill.test.ts</files>
  <action>
Create `src/knowledge/wiki-backfill.ts` following the same patterns as `review-comment-backfill.ts` -- a module-level engine function with types for options and results.

**Types:**

```typescript
export type WikiBackfillResult = {
  totalPages: number;
  totalChunks: number;
  totalEmbeddings: number;
  skippedPages: number;      // redirects, stubs, disambiguation
  durationMs: number;
  resumed: boolean;
};

export type WikiBackfillOptions = {
  store: WikiPageStore;
  embeddingProvider: EmbeddingProvider;
  source: string;            // e.g. "kodi.wiki"
  baseUrl?: string;          // Default: "https://kodi.wiki"
  namespaces?: string[];     // Filter to specific namespaces (empty = all)
  logger: Logger;
  dryRun?: boolean;
  delayMs?: number;          // Delay between API requests (default: 500ms)
};
```

**MediaWiki API integration:**

Use the MediaWiki Action API (no external library -- plain fetch):

1. **List all pages** via `action=query&list=allpages`:
   - URL: `${baseUrl}/w/api.php?action=query&list=allpages&aplimit=50&format=json`
   - Paginate using `apcontinue` token from response
   - If `namespaces` filter provided, use `apnamespace` parameter

2. **Fetch page content** via `action=parse`:
   - URL: `${baseUrl}/w/api.php?action=parse&pageid=${pageId}&prop=text|revid|displaytitle|categories&format=json`
   - This returns rendered HTML in `parse.text["*"]`
   - Extract `revisionId` from `parse.revid`
   - Extract page URL: `${baseUrl}/view/${encodeURIComponent(pageTitle)}`

3. **Rate limiting:**
   - Apply configurable delay between requests (default 500ms)
   - Respect any Retry-After headers
   - Log rate limit events

**Backfill algorithm:**

```
async function backfillWikiPages(opts: WikiBackfillOptions): Promise<WikiBackfillResult>
```

1. Check sync state: `store.getSyncState(source)`
   - If `backfillComplete` is true: log "Backfill already complete" and return early
   - If `lastContinueToken` exists: resume from that token (set `resumed = true`)
2. Fetch page list using allpages API with pagination
3. For each page:
   a. Check if page already exists with same revision: `store.getPageRevision(pageId)`
      - If revision matches, skip (already ingested)
   b. Fetch page content via parse API
   c. Build `WikiPageInput` from API response
   d. Call `chunkWikiPage(pageInput)` -- returns chunks (may be empty for redirects/stubs)
   e. If chunks empty, increment `skippedPages`, continue
   f. For each chunk, call `embeddingProvider.generate(chunk.chunkText, "document")`
      - Mutate `chunk.embedding` in-place (same pattern as review comment backfill)
   g. If not dryRun: call `store.replacePageChunks(pageId, chunks)` (handles re-ingestion)
   h. Update sync state with progress (every 10 pages)
   i. Apply rate delay between page fetches
   j. Log progress every 50 pages: `"Wiki backfill progress" { pagesProcessed, chunksWritten, skipped }`
4. After all pages: mark `backfillComplete = true` in sync state
5. Return `WikiBackfillResult`

**Error handling:**
- Individual page fetch failures: log warning, continue to next page (fail-open)
- API errors (5xx): retry once with exponential backoff, then skip page
- Embedding failures: store chunk without embedding (stale = true), continue

**Tests:**

Unit tests using mocked fetch and store:
- Fetches page list with pagination (mock allpages API response)
- Fetches individual page content (mock parse API response)
- Skips pages with matching revision (no re-ingestion)
- Resumes from last continue token
- Respects rate delay between requests
- Handles API errors gracefully (continues on failure)
- Dry run mode fetches but does not store
- Chunks are embedded before storage
- Skipped pages counted in result
- Backfill marks complete when finished
  </action>
  <verify>
- `bun test src/knowledge/wiki-backfill.test.ts` passes
- All existing tests still pass: `bun test`
  </verify>
  <done>
- Backfill engine fetches all pages from MediaWiki API
- Pagination handles the full page list
- Resume from sync state works on restart
- Rate limiting prevents API overload
- Pages are chunked, embedded, and stored
- Redirects, stubs, disambiguation pages skipped
  </done>
</task>

<task type="auto">
  <name>Task 2: Create backfill CLI and update barrel exports</name>
  <files>scripts/backfill-wiki.ts, src/knowledge/index.ts, package.json</files>
  <action>
**CLI (`scripts/backfill-wiki.ts`):**

Create following the exact same pattern as `scripts/backfill-review-comments.ts`:

```typescript
/**
 * CLI entry point for backfilling wiki pages from MediaWiki API.
 *
 * Usage:
 *   bun scripts/backfill-wiki.ts                              # Full backfill from kodi.wiki
 *   bun scripts/backfill-wiki.ts --source kodi.wiki           # Explicit source
 *   bun scripts/backfill-wiki.ts --namespace Main             # Only Main namespace
 *   bun scripts/backfill-wiki.ts --dry-run                    # Fetch and log, don't store
 *
 * Environment variables required:
 *   DATABASE_URL          - PostgreSQL connection string
 *   VOYAGE_API_KEY        - VoyageAI API key (optional, embeddings disabled without it)
 */
```

Arguments using `node:util` `parseArgs`:
- `--source <name>` - Wiki source identifier (default: "kodi.wiki")
- `--base-url <url>` - MediaWiki base URL (default: "https://kodi.wiki")
- `--namespace <name>` - Filter to specific namespace (can be repeated, default: all)
- `--delay <ms>` - Delay between API requests in ms (default: 500)
- `--dry-run` - Fetch and log but don't store
- `--help` - Show usage

Setup:
1. Validate DATABASE_URL environment variable
2. Create DB client and run migrations
3. Create wiki page store
4. Create embedding provider (voyage-code-3, 1024 dims, or no-op if no VOYAGE_API_KEY)
5. No GitHub App needed (unlike review comment backfill -- wiki uses public MediaWiki API)

Execute `backfillWikiPages()` and print results:
```
Wiki backfill complete.
  Total pages:    ${result.totalPages}
  Total chunks:   ${result.totalChunks}
  Total embeddings: ${result.totalEmbeddings}
  Skipped pages:  ${result.skippedPages}
  Duration:       ${(result.durationMs / 1000).toFixed(1)}s
  Resumed:        ${result.resumed}
```

Close DB connection in `finally` block.

**Package.json:**

Add script entry:
```json
"backfill:wiki": "bun scripts/backfill-wiki.ts"
```

**Barrel exports (`src/knowledge/index.ts`):**

Add exports for all wiki modules:
```typescript
export { createWikiPageStore } from "./wiki-store.ts";
export type { WikiPageStore, WikiPageChunk, WikiPageInput, WikiPageRecord, WikiPageSearchResult, WikiSyncState } from "./wiki-types.ts";
export { chunkWikiPage, stripHtmlToMarkdown } from "./wiki-chunker.ts";
export { backfillWikiPages } from "./wiki-backfill.ts";
export type { WikiBackfillResult, WikiBackfillOptions } from "./wiki-backfill.ts";
```
  </action>
  <verify>
- `bun scripts/backfill-wiki.ts --help` prints usage
- `bun scripts/backfill-wiki.ts --dry-run` runs without errors (requires DATABASE_URL, no wiki access needed for dry-run with empty DB)
- `bun test` all existing tests pass
- TypeScript compiles without errors
  </verify>
  <done>
- CLI provides same UX as `npm run backfill:reviews` with progress and resume support
- `npm run backfill:wiki` command available in package.json
- All wiki modules exported from barrel
- No new dependencies required (uses built-in fetch)
  </done>
</task>

</tasks>

<verification>
- Backfill engine fetches from MediaWiki API with pagination and rate limiting
- Resume works from sync state on restart
- CLI provides --source, --namespace, --dry-run, --delay flags
- Pages are chunked, embedded, and stored in wiki_pages table
- Redirect/stub/disambiguation pages filtered during backfill
- All existing tests continue to pass
</verification>

<success_criteria>
- `npm run backfill:wiki` can ingest all kodi.wiki pages
- Backfill is resumable and idempotent
- Rate limiting prevents overloading the MediaWiki API
- Progress is logged with page counts and timing
</success_criteria>

<output>
After completion, create `.planning/phases/90-mediawiki-content-ingestion/90-02-SUMMARY.md`
</output>
