---
phase: 86-postgresql-pgvector-on-azure
plan: 03
type: execute
wave: 2
depends_on:
  - 86-01
files_modified:
  - src/learning/memory-store.ts
  - src/learning/memory-store.test.ts
  - src/learning/retrieval-query.ts
  - src/learning/retrieval-query.test.ts
  - src/learning/retrieval-rerank.ts
  - src/learning/retrieval-rerank.test.ts
  - src/learning/multi-query-retrieval.ts
  - src/learning/multi-query-retrieval.test.ts
autonomous: true
requirements:
  - DB-04
  - DB-05
  - DB-08
  - DB-09

must_haves:
  truths:
    - "LearningMemoryStore uses postgres.js + pgvector for all vector operations"
    - "Vector similarity queries use HNSW index with cosine distance operator"
    - "No sqlite-vec or bun:sqlite imports remain in src/learning/"
    - "writeMemory stores embeddings as vector(1024) column values"
    - "retrieveMemories uses pgvector <=> operator for cosine distance search"
    - "retrieveMemoriesForOwner queries across repo partitions using pgvector"
    - "All retrieval pipeline modules updated for async postgres.js calls"
  artifacts:
    - path: "src/learning/memory-store.ts"
      provides: "PostgreSQL + pgvector backed LearningMemoryStore"
      exports: ["createLearningMemoryStore"]
    - path: "src/learning/retrieval-query.ts"
      provides: "Retrieval query module using async store"
  key_links:
    - from: "src/learning/memory-store.ts"
      to: "src/db/client.ts"
      via: "accepts sql instance"
      pattern: "import.*sql.*from.*db/client"
    - from: "src/learning/memory-store.ts"
      to: "pgvector HNSW index"
      via: "cosine distance operator <=>"
      pattern: "<=>"
---

<objective>
Port the LearningMemoryStore from sqlite-vec to postgres.js + pgvector. Replace the vec0 virtual table with native pgvector vector columns and HNSW index queries. Update all retrieval pipeline modules that depend on the store.

Purpose: Eliminate the sqlite-vec dependency and use pgvector's native HNSW indexes for vector similarity search, which is the core capability enabling learning memory retrieval.

Output: Rewritten memory-store.ts using pgvector, updated retrieval pipeline modules, passing tests.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/86-postgresql-pgvector-on-azure/86-01-SUMMARY.md
@src/learning/types.ts
@src/learning/memory-store.ts
@src/learning/retrieval-query.ts
@src/learning/retrieval-rerank.ts
@src/learning/multi-query-retrieval.ts
@src/db/client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite LearningMemoryStore to use pgvector</name>
  <files>
    src/learning/memory-store.ts
    src/learning/memory-store.test.ts
    src/learning/types.ts
  </files>
  <action>
1. **Rewrite `src/learning/memory-store.ts`**:
   - Change factory signature: `createLearningMemoryStore(opts: { sql: Sql; logger: Logger }): LearningMemoryStore`
   - Remove ALL `bun:sqlite` imports, `require("sqlite-vec")` call, and vec0 virtual table creation
   - Remove the `createNoOpStore` fallback -- pgvector is always available in our PostgreSQL setup (no fail-open needed for extension loading)
   - Remove ALL table creation DDL (schema now in migrations, including the `learning_memories` table with `embedding vector(1024)` column)

   **writeMemory implementation:**
   - Convert `Float32Array` to a pgvector-compatible string format: `[0.1, 0.2, ...]`
   - Insert into `learning_memories` including the `embedding` column:
     ```sql
     INSERT INTO learning_memories (repo, owner, finding_id, review_id, source_repo, finding_text, severity, category, file_path, outcome, embedding_model, embedding_dim, stale, embedding)
     VALUES (${...}, ..., ${embeddingString}::vector)
     ON CONFLICT (repo, finding_id, outcome) DO NOTHING
     ```

   **retrieveMemories implementation:**
   - Replace sqlite-vec `MATCH` query with pgvector cosine distance:
     ```sql
     SELECT m.id AS memory_id, m.embedding <=> ${queryEmbeddingString}::vector AS distance
     FROM learning_memories m
     WHERE m.repo = ${repo} AND m.stale = false
     ORDER BY m.embedding <=> ${queryEmbeddingString}::vector
     LIMIT ${topK}
     ```
   - The `<=>` operator uses the HNSW index automatically for cosine distance

   **retrieveMemoriesForOwner implementation:**
   - Same pattern: find repos for owner, then query each repo with pgvector `<=>` operator
   - Merge, deduplicate, sort by distance, take topK
   - This can potentially be done in a single query with `WHERE m.owner = ${owner} AND m.repo != ${excludeRepo}` but keep the per-repo approach for now to match existing behavior

   **Embedding format conversion:**
   - Create helper: `function float32ArrayToVectorString(arr: Float32Array): string` that returns `[0.1,0.2,...]` format
   - Create helper: `function vectorStringToFloat32Array(str: string): Float32Array` (if needed for reads)

   **Make all methods async.** Update `LearningMemoryStore` type in `src/learning/types.ts`:
   - `writeMemory` -> `Promise<void>`
   - `retrieveMemories` -> `Promise<{ memoryId: number; distance: number }[]>`
   - `retrieveMemoriesForOwner` -> `Promise<{ memoryId: number; distance: number }[]>`
   - `getMemoryRecord` -> `Promise<LearningMemoryRecord | null>`
   - `markStale` -> `Promise<number>`
   - `purgeStaleEmbeddings` -> `Promise<number>`

   **markStale + purgeStaleEmbeddings:**
   - No separate vec table to clean up -- just `UPDATE learning_memories SET stale = true WHERE embedding_model != ${model} AND stale = false`
   - Purge: `DELETE FROM learning_memories WHERE stale = true`

2. **Update `src/learning/memory-store.test.ts`**:
   - Connect to Docker Compose PostgreSQL
   - Run migrations before tests
   - Test writeMemory with a real 1024-dim Float32Array
   - Test retrieveMemories returns nearest neighbors
   - Test retrieveMemoriesForOwner works cross-repo
   - Test markStale + purgeStaleEmbeddings
   - Test duplicate write is silently ignored (ON CONFLICT DO NOTHING)
  </action>
  <verify>
`DATABASE_URL=postgresql://kodiai:kodiai@localhost:5432/kodiai bun test src/learning/memory-store` passes. `grep -r "sqlite-vec\|bun:sqlite" src/learning/` returns no matches. Vector similarity query returns results ordered by cosine distance.
  </verify>
  <done>
LearningMemoryStore uses pgvector for all vector operations. HNSW index is used for cosine distance queries. No sqlite-vec or bun:sqlite imports remain. Write and retrieval operations work with Float32Array embeddings.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update retrieval pipeline modules for async store interface</name>
  <files>
    src/learning/retrieval-query.ts
    src/learning/retrieval-query.test.ts
    src/learning/retrieval-rerank.ts
    src/learning/retrieval-rerank.test.ts
    src/learning/multi-query-retrieval.ts
    src/learning/multi-query-retrieval.test.ts
    src/learning/retrieval-recency.ts
    src/learning/retrieval-recency.test.ts
    src/learning/retrieval-snippets.ts
    src/learning/retrieval-snippets.test.ts
    src/learning/isolation.ts
  </files>
  <action>
1. **Update all retrieval pipeline modules** that call `LearningMemoryStore` methods. Since the store methods are now async, every call site must be awaited:
   - `store.retrieveMemories(...)` -> `await store.retrieveMemories(...)`
   - `store.getMemoryRecord(...)` -> `await store.getMemoryRecord(...)`
   - `store.writeMemory(...)` -> `await store.writeMemory(...)`
   - `store.retrieveMemoriesForOwner(...)` -> `await store.retrieveMemoriesForOwner(...)`

2. **For each file, the approach is:**
   - Read the file, find all `LearningMemoryStore` method calls
   - Add `await` to each call
   - Make the containing function `async` if not already
   - Update the return type to `Promise<...>` if it changed
   - Propagate async up the call chain as needed

3. **Update `src/learning/isolation.ts`**: The isolation layer wraps the memory store. All its methods that call store methods must become async.

4. **Update all corresponding test files** to use `async/await` where store methods are called. Tests that mock the store should return `Promise.resolve(...)` from mocked methods.

5. **Do NOT change the retrieval logic** -- only the async wrapper. The reranking algorithms, recency scoring, snippet extraction, and multi-query expansion logic remain identical.
  </action>
  <verify>
`DATABASE_URL=postgresql://kodiai:kodiai@localhost:5432/kodiai bun test src/learning/` -- all tests pass. `bunx tsc --noEmit` passes. `grep -r "bun:sqlite\|sqlite-vec" src/learning/` returns no matches.
  </verify>
  <done>
All retrieval pipeline modules updated for async store interface. No synchronous store calls remain. Tests pass. TypeScript compiles cleanly.
  </done>
</task>

</tasks>

<verification>
1. `grep -r "bun:sqlite\|sqlite-vec" src/learning/` returns zero matches
2. `DATABASE_URL=postgresql://kodiai:kodiai@localhost:5432/kodiai bun test src/learning/` all pass
3. `bunx tsc --noEmit` passes
4. Vector similarity search returns results sorted by cosine distance
5. HNSW index is used (can verify with `EXPLAIN ANALYZE` in test)
</verification>

<success_criteria>
- LearningMemoryStore fully ported to pgvector
- Vector queries use <=> cosine distance operator hitting HNSW index
- All retrieval pipeline modules updated for async interface
- sqlite-vec dependency ready for removal (no imports remain)
- All tests pass against Docker Compose PostgreSQL
</success_criteria>

<output>
After completion, create `.planning/phases/86-postgresql-pgvector-on-azure/86-03-SUMMARY.md`
</output>
