---
phase: 95-ci-failure-recognition
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/db/migrations/008-ci-check-history.sql
  - src/db/migrations/008-ci-check-history.down.sql
  - src/lib/ci-check-store.ts
  - src/lib/ci-failure-classifier.ts
  - src/lib/ci-failure-classifier.test.ts
autonomous: true
requirements: [CIFR-01, CIFR-02, CIFR-05]

must_haves:
  truths:
    - "CI check history table exists with repo, check_name, head_sha, conclusion columns and a composite index"
    - "Flakiness query returns rolling-window stats (failures/total) for the last 20 runs per check name per repo"
    - "Classifier labels a failure as 'unrelated' (high confidence) when the same check name also fails on a base-branch commit"
    - "Classifier labels a failure as 'flaky-unrelated' (medium confidence) when its flakiness rate exceeds 30% over 20 runs"
    - "Classifier labels a failure as 'possibly-pr-related' (low confidence) by default when it passes on base and is not flaky"
    - "Classifier returns empty array when all checks pass (no failures to classify)"
  artifacts:
    - path: "src/db/migrations/008-ci-check-history.sql"
      provides: "ci_check_history table DDL"
      contains: "CREATE TABLE"
    - path: "src/lib/ci-check-store.ts"
      provides: "recordCheckRun + getFlakiness + getBaseResults functions"
      exports: ["recordCheckRuns", "getFlakiness"]
    - path: "src/lib/ci-failure-classifier.ts"
      provides: "Pure classification function"
      exports: ["classifyFailures", "ClassifiedFailure"]
    - path: "src/lib/ci-failure-classifier.test.ts"
      provides: "Unit tests for classifier"
      min_lines: 80
  key_links:
    - from: "src/lib/ci-failure-classifier.ts"
      to: "src/lib/ci-check-store.ts"
      via: "flakiness data consumed by classifier"
      pattern: "getFlakiness|FlakinessStat"
---

<objective>
Create the CI check history database table, flakiness store module, and pure classification logic for comparing PR check failures against base-branch results.

Purpose: Provides the deterministic classification engine (unrelated / flaky-unrelated / possibly-pr-related) that the handler (Plan 02) will invoke. TDD approach ensures correctness of classification edge cases.
Output: Migration 008, ci-check-store.ts, ci-failure-classifier.ts with tests
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/95-ci-failure-recognition/95-CONTEXT.md
@.planning/phases/95-ci-failure-recognition/95-RESEARCH.md

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/db/client.ts:
```typescript
export type Sql = ReturnType<typeof postgres>;
```

From src/db/migrations/ (pattern — follow existing naming):
```
001-initial-schema.sql / .down.sql
002-pgvector-indexes.sql / .down.sql
...
007-language-column.sql / .down.sql
// Next: 008-ci-check-history.sql / .down.sql
```

From src/db/migrate.ts (migrations auto-discovered from directory):
```typescript
// Migrations run in filename order. Just create the .sql files.
import type { Sql } from "./client.ts";
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database migration and flakiness store</name>
  <files>
    src/db/migrations/008-ci-check-history.sql
    src/db/migrations/008-ci-check-history.down.sql
    src/lib/ci-check-store.ts
  </files>
  <action>
Create migration 008-ci-check-history.sql with:

```sql
CREATE TABLE IF NOT EXISTS ci_check_history (
  id BIGSERIAL PRIMARY KEY,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  repo TEXT NOT NULL,
  check_name TEXT NOT NULL,
  head_sha TEXT NOT NULL,
  conclusion TEXT NOT NULL,  -- 'success', 'failure', 'neutral', 'cancelled', 'timed_out', 'action_required', 'stale', 'skipped'
  check_suite_id BIGINT,
  pr_number INTEGER          -- NULL for non-PR runs
);

CREATE INDEX idx_ci_check_history_repo_name
  ON ci_check_history(repo, check_name, created_at DESC);
```

Create down migration:
```sql
DROP TABLE IF EXISTS ci_check_history;
```

Create `src/lib/ci-check-store.ts` with:

1. `recordCheckRuns(sql, params: { repo, headSha, prNumber?, checkSuiteId?, runs: Array<{ name, conclusion }> })` — bulk-inserts rows into ci_check_history. Uses a single SQL INSERT with multiple value rows for efficiency.

2. `getFlakiness(sql, params: { repo, checkNames: string[] }): Promise<Map<string, { failures: number; total: number }>>` — for each check name, queries the last 20 rows (ORDER BY created_at DESC LIMIT 20) and counts failures. Returns a Map keyed by check_name. If a check has no history, it is absent from the Map.

Import `Sql` from `../db/client.ts`. Use tagged template SQL (the `sql` client is postgres.js).

Do NOT use an ORM. Follow the same raw-SQL pattern used in `src/knowledge/store.ts` and `src/telemetry/store.ts`.
  </action>
  <verify>
    <automated>bun run src/db/migrations/008-ci-check-history.sql 2>/dev/null; test -f src/db/migrations/008-ci-check-history.sql && test -f src/db/migrations/008-ci-check-history.down.sql && test -f src/lib/ci-check-store.ts && echo "PASS" || echo "FAIL"</automated>
  </verify>
  <done>
    - 008 migration creates ci_check_history table with repo, check_name, head_sha, conclusion columns and composite index
    - Down migration drops the table
    - ci-check-store.ts exports recordCheckRuns and getFlakiness functions using postgres.js tagged templates
    - getFlakiness returns rolling window of last 20 runs per check name
  </done>
</task>

<task type="auto">
  <name>Task 2: CI failure classifier with TDD tests</name>
  <files>
    src/lib/ci-failure-classifier.ts
    src/lib/ci-failure-classifier.test.ts
  </files>
  <action>
**RED phase first** — write tests in `src/lib/ci-failure-classifier.test.ts` before implementation.

Define and export from `src/lib/ci-failure-classifier.ts`:

```typescript
export type CheckResult = { name: string; conclusion: string | null; status: string };

export type Classification = "unrelated" | "flaky-unrelated" | "possibly-pr-related";
export type Confidence = "high" | "medium" | "low";

export type ClassifiedFailure = {
  checkName: string;
  classification: Classification;
  confidence: Confidence;
  evidence: string;
  flakiness?: { failRate: number; window: number };
};

export type FlakinessStat = { failures: number; total: number };

export function classifyFailures(params: {
  headChecks: CheckResult[];
  baseResults: Map<string, CheckResult[]>;  // keyed by commit SHA
  flakiness: Map<string, FlakinessStat>;
}): ClassifiedFailure[];
```

Classification rules (locked decisions from CONTEXT.md):
1. Filter `headChecks` to only those with `conclusion === "failure"`.
2. For each head failure, check if ANY base commit has the same check name with `conclusion === "failure"`. If yes → `{ classification: "unrelated", confidence: "high", evidence: "Also fails on <baseRef>@<sha7>" }`.
3. If not found on base, check flakiness: if `total >= 20` AND `failures / total > 0.3` → `{ classification: "flaky-unrelated", confidence: "medium", evidence: "Historically flaky", flakiness: { failRate, window } }`.
4. Otherwise → `{ classification: "possibly-pr-related", confidence: "low", evidence: "Passes on base branch" }`.
5. Return empty array when no failures exist in headChecks.

**Test cases (write FIRST, then implement to pass):**

1. **All checks pass** — headChecks all have `conclusion: "success"` → returns `[]`
2. **Base-branch match** — check "build" fails on head and on base commit "abc1234" → `unrelated`, high confidence, evidence includes "abc1234" (first 7 chars)
3. **Flaky override** — check "flaky-lint" fails on head, passes on all base commits, flakiness shows 8/20 failures → `flaky-unrelated`, medium confidence, flakiness stats included
4. **PR-related default** — check "test-suite" fails on head, passes on all base commits, no flakiness data → `possibly-pr-related`, low confidence
5. **Mixed scenario** — 3 failures: one base-match, one flaky, one PR-related → correct classification for each
6. **Flaky below threshold** — check fails on head, flakiness shows 5/20 (25%) → NOT flaky-unrelated, falls to possibly-pr-related
7. **Flaky insufficient data** — check fails on head, flakiness shows 3/10 (30% rate but only 10 runs) → NOT flaky-unrelated (total < 20)
8. **No base results at all** — empty `baseResults` Map → all failures classified as possibly-pr-related (or flaky if applicable)

Use `bun:test` (`import { describe, it, expect } from "bun:test"`). Follow existing test patterns in the project.
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && bun test src/lib/ci-failure-classifier.test.ts</automated>
  </verify>
  <done>
    - ci-failure-classifier.ts exports classifyFailures, ClassifiedFailure, CheckResult, FlakinessStat types
    - All 8 test cases pass covering: all-pass, base-match, flaky override, PR-related default, mixed, below-threshold, insufficient-data, no-base-results
    - Classification logic matches locked decisions exactly: base-branch match → unrelated/high, flaky >30% with 20+ runs → flaky-unrelated/medium, default → possibly-pr-related/low
  </done>
</task>

</tasks>

<verification>
- `bun test src/lib/ci-failure-classifier.test.ts` passes all 8+ test cases
- Migration files exist: `src/db/migrations/008-ci-check-history.sql` and `.down.sql`
- `src/lib/ci-check-store.ts` exports `recordCheckRuns` and `getFlakiness`
- `src/lib/ci-failure-classifier.ts` exports `classifyFailures` and all types
- No modifications to existing files (all new files)
</verification>

<success_criteria>
Pure classification logic is fully tested and correct. Database migration is ready to run. Flakiness store provides the data access layer. Plan 02 can build the handler on top of these foundations.
</success_criteria>

<output>
After completion, create `.planning/phases/95-ci-failure-recognition/95-01-SUMMARY.md`
</output>
