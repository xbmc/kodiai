---
title: "99-02: Wiki Staleness Types + Core Detector Module"
phase: 99
plan: 2
wave: 2
depends_on:
  - 99-01
files_modified:
  - src/knowledge/wiki-staleness-types.ts
  - src/knowledge/wiki-staleness-detector.ts
  - src/knowledge/wiki-staleness-detector.test.ts
autonomous: true
requirements:
  - WIKI-01
  - WIKI-02
  - WIKI-05
---

# Plan 99-02: Core Staleness Detector — Types and Two-Tier Pipeline

## Goal

Create the core wiki staleness detection module:
1. `wiki-staleness-types.ts` — all type definitions
2. `wiki-staleness-detector.ts` — the `createWikiStalenessDetector` factory with: GitHub commit fetching, heuristic pass, LLM evaluation (capped at 20), result assembly
3. `wiki-staleness-detector.test.ts` — unit tests for heuristic scoring and pipeline behavior

## Context

- The two-tier pipeline is: collect changed files from GitHub → heuristic score all wiki pages → LLM-evaluate top candidates (cap 20) → return stale pages with evidence.
- `TASK_TYPES.STALENESS_EVIDENCE` is already defined in `src/llm/task-types.ts` as non-agentic.
- `generateWithFallback()` in `src/llm/generate.ts` is the LLM call wrapper.
- `createTaskRouter()` from `src/llm/task-router.ts` resolves `staleness.evidence` to a Haiku-tier model by default.
- `WikiPageStore` has `countBySource()` (for empty-store guard) and needs a new method to list all active pages grouped by page_id.
- `wiki_pages` stores CHUNKS — group by `page_id` before heuristic scoring (see RESEARCH.md Pitfall 3).
- GitHub commits: use `octokit.paginate(octokit.repos.listCommits, { owner, repo, since, per_page: 100 })` then `octokit.repos.getCommit` for file-level detail. Cap scan window at 7 days (config: `wikiStalenessThresholdDays`).
- Confidence tiers: heuristic score >= 3 → "High", >= 1 → "Medium". LLM result is the explanation text.
- Pages deferred (beyond 20-page cap) are NOT included in report — silently defer to next cycle.
- On empty wiki store: skip scan entirely, do not post report.

## Tasks

<task id="99-02-A" wave="1">
### Create src/knowledge/wiki-staleness-types.ts

Create this file with all type definitions for the staleness detector:

```typescript
import type { Logger } from "pino";
import type { Sql } from "../db/client.ts";
import type { WikiPageStore } from "./wiki-types.ts";
import type { TaskRouter } from "../llm/task-router.ts";
import type { CostTracker } from "../llm/cost-tracker.ts";
import type { GitHubApp } from "../auth/github-app.ts";
import type { SlackClient } from "../slack/client.ts";

/** A single wiki page candidate (grouped from wiki_pages chunks). */
export type WikiPageCandidate = {
  pageId: number;
  pageTitle: string;
  pageUrl: string;
  /** Representative chunk texts (up to 3, for LLM evaluation). */
  chunkTexts: string[];
  /** Heuristic score: count of path-token overlaps with changed files. */
  heuristicScore: number;
  /** Confidence tier from heuristic: "High" | "Medium" */
  heuristicTier: "High" | "Medium";
  /** The commit SHA(s) most recently associated with score contribution. */
  affectingCommitShas: string[];
  /** The changed file path(s) that contributed to the heuristic score. */
  affectingFilePaths: string[];
  /**
   * Unix timestamp (ms) of the most recent commit that contributed to this
   * candidate's score. Used as primary sort key for LLM evaluation ordering
   * when the 20-page cap applies (recency-first per locked decision).
   */
  sortableRecencyMs: number;
};

/** A confirmed stale page after LLM evaluation. */
export type StalePage = {
  pageId: number;
  pageTitle: string;
  pageUrl: string;
  /** Confidence tier (may be upgraded/downgraded by LLM). */
  confidence: "High" | "Medium" | "Low";
  /** One-line LLM-generated explanation of why the page is stale. */
  explanation: string;
  /** Commit SHA of most recent affecting commit. */
  commitSha: string;
  /** File path that most directly triggered staleness. */
  changedFilePath: string;
};

/** Result from a single staleness scan run. */
export type WikiStalenessScanResult = {
  pagesScanned: number;
  pagesFlagged: number;
  pagesEvaluated: number;
  stalePages: StalePage[];
  durationMs: number;
  skipped: boolean;
  skipReason?: string;
};

/** Run state record stored in wiki_staleness_run_state table. */
export type WikiStalenessRunState = {
  id?: number;
  lastRunAt: Date | null;
  lastCommitSha: string | null;
  pagesFlagged: number;
  pagesEvaluated: number;
  status: "success" | "failed" | "pending";
  errorMessage: string | null;
  updatedAt?: string;
};

/** Options for creating a wiki staleness detector. */
export type WikiStalenessDetectorOptions = {
  sql: Sql;
  wikiPageStore: WikiPageStore;
  githubApp: GitHubApp;
  slackClient: SlackClient;
  taskRouter: TaskRouter;
  costTracker?: CostTracker;
  logger: Logger;
  /** GitHub owner for commit scanning (e.g. "xbmc"). */
  githubOwner: string;
  /** GitHub repo for commit scanning (e.g. "xbmc"). */
  githubRepo: string;
  /** Slack channel ID to post reports to (e.g. "C12345"). */
  wikiChannelId: string;
  /** Days to look back for commits (default 30). Controls scan window cap. */
  stalenessThresholdDays: number;
  /** Interval override for testing (ms). Default: 7 days. */
  intervalMs?: number;
  /** Startup delay override for testing (ms). Default: 90s. */
  delayMs?: number;
};

/** Public interface returned by createWikiStalenessDetector. */
export type WikiStalenessScheduler = {
  start(): void;
  stop(): void;
  runScan(): Promise<WikiStalenessScanResult>;
};
```
</task>

<task id="99-02-B" wave="2">
### Create src/knowledge/wiki-staleness-detector.ts

**Dependencies:** Requires 99-02-A (types) and 99-01-A (migration defines the DB table shape).

Create `src/knowledge/wiki-staleness-detector.ts`. The module exports one function: `createWikiStalenessDetector`.

#### Structure

```typescript
import type { Logger } from "pino";
import type { Octokit } from "@octokit/rest";
import { generateWithFallback } from "../llm/generate.ts";
import { TASK_TYPES } from "../llm/task-types.ts";
import type {
  WikiStalenessDetectorOptions,
  WikiStalenessScheduler,
  WikiStalenessScanResult,
  WikiPageCandidate,
  StalePage,
  WikiStalenessRunState,
} from "./wiki-staleness-types.ts";

const DEFAULT_INTERVAL_MS = 7 * 24 * 60 * 60 * 1000; // 7 days
const DEFAULT_STARTUP_DELAY_MS = 90_000; // 90 seconds
const LLM_CAP = 20; // max pages to LLM-evaluate per cycle
const MAX_SCAN_WINDOW_DAYS = 7; // cap on commit scan window regardless of threshold

export function createWikiStalenessDetector(
  opts: WikiStalenessDetectorOptions,
): WikiStalenessScheduler { ... }
```

#### Internal helpers to implement

**1. `loadRunState(sql): Promise<WikiStalenessRunState>`**

Load the single-row run state from `wiki_staleness_run_state`:

```typescript
async function loadRunState(sql: Sql): Promise<WikiStalenessRunState> {
  const rows = await sql`SELECT * FROM wiki_staleness_run_state WHERE id = 1`;
  if (rows.length === 0) {
    return { lastRunAt: null, lastCommitSha: null, pagesFlagged: 0, pagesEvaluated: 0, status: "pending", errorMessage: null };
  }
  const row = rows[0]!;
  return {
    id: row.id as number,
    lastRunAt: row.last_run_at ? new Date(row.last_run_at as string) : null,
    lastCommitSha: (row.last_commit_sha as string) ?? null,
    pagesFlagged: row.pages_flagged as number,
    pagesEvaluated: row.pages_evaluated as number,
    status: row.status as WikiStalenessRunState["status"],
    errorMessage: (row.error_message as string) ?? null,
    updatedAt: row.updated_at as string,
  };
}
```

**2. `saveRunState(sql, state): Promise<void>`**

Upsert into id=1:

```typescript
async function saveRunState(sql: Sql, state: WikiStalenessRunState): Promise<void> {
  await sql`
    INSERT INTO wiki_staleness_run_state (id, last_run_at, last_commit_sha, pages_flagged, pages_evaluated, status, error_message, updated_at)
    VALUES (1, ${state.lastRunAt}, ${state.lastCommitSha}, ${state.pagesFlagged}, ${state.pagesEvaluated}, ${state.status}, ${state.errorMessage}, now())
    ON CONFLICT (id) DO UPDATE SET
      last_run_at = EXCLUDED.last_run_at,
      last_commit_sha = EXCLUDED.last_commit_sha,
      pages_flagged = EXCLUDED.pages_flagged,
      pages_evaluated = EXCLUDED.pages_evaluated,
      status = EXCLUDED.status,
      error_message = EXCLUDED.error_message,
      updated_at = now()
  `;
}
```

**3. `fetchChangedFiles(octokit, owner, repo, since): Promise<Array<{ sha: string; files: string[] }>>`**

Get changed file paths per commit since `since` date. Cap at 7-day window:

```typescript
async function fetchChangedFiles(
  octokit: Octokit,
  owner: string,
  repo: string,
  since: Date,
  logger: Logger,
): Promise<Array<{ sha: string; files: string[] }>> {
  // Use listCommits with since param; per_page: 100 (paginated)
  // For each commit, call getCommit to get file list
  // Returns array of { sha, files: string[] }
  // Cap total commits at 200 to prevent runaway API calls
}
```

Implementation notes:
- Use `octokit.paginate(octokit.repos.listCommits, { owner, repo, since: since.toISOString(), per_page: 100 })` to list commits
- For each commit SHA, call `octokit.repos.getCommit({ owner, repo, ref: sha })` to get `data.files[].filename`
- Cap total commits at 200 before fetching detail (to avoid rate limits on large gaps)
- Catch and log individual `getCommit` failures but continue (fail-open)

**4. `heuristicScore(chunkTexts: string[], changedFilePaths: string[]): number`**

Token overlap between wiki chunk text and changed file paths:

```typescript
function heuristicScore(chunkTexts: string[], changedFilePaths: string[]): number {
  // Extract all tokens from all chunks
  const chunkTokens = new Set<string>();
  for (const text of chunkTexts) {
    for (const t of text.toLowerCase().split(/\W+/)) {
      if (t.length > 3) chunkTokens.add(t);
    }
  }

  let score = 0;
  for (const filePath of changedFilePaths) {
    const pathTokens = filePath.toLowerCase().split(/[/._-]+/).filter(t => t.length > 3);
    for (const token of pathTokens) {
      if (chunkTokens.has(token)) score++;
    }
  }
  return score;
}
```

**5. `heuristicPass(wikiPageStore, changedCommits): Promise<WikiPageCandidate[]>`**

Query wiki pages, group by `page_id`, score each page:

```typescript
async function heuristicPass(
  sql: Sql,
  changedCommits: Array<{ sha: string; files: string[] }>,
  logger: Logger,
): Promise<WikiPageCandidate[]> {
  // Query distinct pages: SELECT DISTINCT ON (page_id) page_id, page_title, page_url FROM wiki_pages WHERE deleted = false AND stale = false ORDER BY page_id, chunk_index
  // For each page, also fetch representative chunks (up to 3) from the same query
  // Build allChangedFiles flat array from changedCommits; build a sha→timestamp map for recency lookup
  // Score each page; if score > 0, include as candidate
  // Determine affectingCommitShas: commits whose files contributed to the score
  // Compute sortableRecencyMs: maximum timestamp (ms) among all affectingCommitShas using the sha→timestamp map
  // Sort candidates: PRIMARY by sortableRecencyMs DESC (most recently affected commits first, per locked decision),
  //                  SECONDARY by heuristicScore DESC
  // Return candidates
}
```

Implementation detail: Use a single SQL query to get one representative row per `page_id` with chunk text:

```sql
SELECT DISTINCT ON (page_id)
  page_id, page_title, page_url, chunk_text
FROM wiki_pages
WHERE deleted = false AND stale = false
ORDER BY page_id, chunk_index
```

Then for the top scoring pages, fetch up to 3 chunk texts per page for LLM context:

```sql
SELECT chunk_text FROM wiki_pages
WHERE page_id = $1 AND deleted = false AND stale = false
ORDER BY chunk_index LIMIT 3
```

Alternatively, do both in one pass: group in-memory after fetching multiple rows per page. Choose the approach that's simpler; the in-memory approach (fetch up to 10 chunks per page, group) is fine for typical wiki sizes.

**Recommended approach:** Fetch all active chunks (with a reasonable limit, e.g., 5000 rows), group by `page_id` in-memory, take first 3 chunk texts per page for heuristic scoring, score, filter score > 0.

**6. `evaluateWithLlm(candidate, taskRouter, generateWithFallback, costTracker, logger): Promise<StalePage | null>`**

LLM call to confirm staleness and generate explanation:

```typescript
async function evaluateWithLlm(
  candidate: WikiPageCandidate,
  taskRouter: ReturnType<typeof createTaskRouter>,
  costTracker: CostTracker | undefined,
  logger: Logger,
): Promise<StalePage | null> {
  const resolved = taskRouter.resolve(TASK_TYPES.STALENESS_EVIDENCE);

  const changedFilesList = candidate.affectingFilePaths.slice(0, 10).join("\n");
  const chunkContent = candidate.chunkTexts.join("\n\n---\n\n");

  const prompt = `You are evaluating whether a wiki page is outdated due to recent code changes.

Wiki page: "${candidate.pageTitle}"
URL: ${candidate.pageUrl}

Wiki content (excerpts):
${chunkContent}

Recently changed code files:
${changedFilesList}

Is this wiki page likely outdated due to these code changes?
- If YES: respond with "STALE: " followed by a single sentence explaining what specifically changed and why the wiki page needs updating (e.g., "STALE: The API endpoint was renamed from /users to /accounts but the wiki still references /users").
- If NO: respond with "CURRENT" (just that word).

Your confidence in this assessment based on file overlap: ${candidate.heuristicTier}.`;

  try {
    const result = await generateWithFallback({
      taskType: TASK_TYPES.STALENESS_EVIDENCE,
      resolved,
      prompt,
      logger,
      costTracker,
    });

    const text = result.text.trim();

    if (text.toUpperCase().startsWith("CURRENT")) {
      return null; // Not stale
    }

    const explanation = text.startsWith("STALE: ") ? text.slice(7).trim() : text;

    // Determine final confidence: LLM said stale, trust heuristic tier unless reasoning suggests low confidence
    const confidence: "High" | "Medium" | "Low" = candidate.heuristicTier;

    return {
      pageId: candidate.pageId,
      pageTitle: candidate.pageTitle,
      pageUrl: candidate.pageUrl,
      confidence,
      explanation,
      commitSha: candidate.affectingCommitShas[0] ?? "",
      changedFilePath: candidate.affectingFilePaths[0] ?? "",
    };
  } catch (err) {
    logger.warn({ err, pageTitle: candidate.pageTitle }, "LLM staleness evaluation failed for page (fail-open)");
    return null;
  }
}
```

#### Main `runScan()` implementation

```typescript
async runScan(): Promise<WikiStalenessScanResult> {
  const startTime = Date.now();

  // Guard: empty wiki store
  const pageCount = await opts.wikiPageStore.countBySource();
  if (pageCount === 0) {
    logger.info("Wiki staleness scan skipped: no wiki pages in store");
    return { pagesScanned: 0, pagesFlagged: 0, pagesEvaluated: 0, stalePages: [], durationMs: 0, skipped: true, skipReason: "empty_wiki_store" };
  }

  // Load run state
  const runState = await loadRunState(opts.sql);

  // Determine scan window: since last successful run (or threshold days ago), cap at MAX_SCAN_WINDOW_DAYS
  const maxWindow = new Date(Date.now() - MAX_SCAN_WINDOW_DAYS * 24 * 60 * 60 * 1000);
  const since = runState.lastRunAt && runState.lastRunAt > maxWindow
    ? runState.lastRunAt
    : maxWindow;

  // Mark run as pending
  await saveRunState(opts.sql, { ...runState, status: "pending", errorMessage: null });

  try {
    // Get GitHub installation
    const installationContext = await opts.githubApp.getRepoInstallationContext(opts.githubOwner, opts.githubRepo);
    if (!installationContext) {
      throw new Error(`GitHub app not installed for ${opts.githubOwner}/${opts.githubRepo}`);
    }
    const octokit = await opts.githubApp.getInstallationOctokit(installationContext.installationId);

    // Fetch changed files from commits
    const changedCommits = await fetchChangedFiles(octokit, opts.githubOwner, opts.githubRepo, since, logger);

    if (changedCommits.length === 0) {
      logger.info({ since }, "Wiki staleness scan: no commits found in window");
      await saveRunState(opts.sql, {
        ...runState,
        lastRunAt: new Date(),
        pagesFlagged: 0,
        pagesEvaluated: 0,
        status: "success",
        errorMessage: null,
      });
      return { pagesScanned: 0, pagesFlagged: 0, pagesEvaluated: 0, stalePages: [], durationMs: Date.now() - startTime, skipped: false };
    }

    // Heuristic pass
    const candidates = await heuristicPass(opts.sql, changedCommits, logger);
    const pagesFlagged = candidates.length;

    // Cap at LLM_CAP (20). Candidates are already sorted by recency DESC primary,
    // heuristicScore DESC secondary (per locked decision: most recently affected commits first).
    const toEvaluate = candidates.slice(0, LLM_CAP);

    // LLM evaluation
    const stalePages: StalePage[] = [];
    for (const candidate of toEvaluate) {
      const result = await evaluateWithLlm(candidate, opts.taskRouter, opts.costTracker, logger);
      if (result) stalePages.push(result);
    }

    // Determine newest commit SHA for scan window anchor
    const newestCommitSha = changedCommits[0]?.sha ?? runState.lastCommitSha;

    await saveRunState(opts.sql, {
      lastRunAt: new Date(),
      lastCommitSha: newestCommitSha ?? null,
      pagesFlagged,
      pagesEvaluated: toEvaluate.length,
      status: "success",
      errorMessage: null,
    });

    const durationMs = Date.now() - startTime;
    logger.info({ pagesFlagged, pagesEvaluated: toEvaluate.length, staleCount: stalePages.length, durationMs }, "Wiki staleness scan complete");

    return {
      pagesScanned: pageCount,
      pagesFlagged,
      pagesEvaluated: toEvaluate.length,
      stalePages,
      durationMs,
      skipped: false,
    };
  } catch (err) {
    const errorMessage = err instanceof Error ? err.message : String(err);
    logger.error({ err }, "Wiki staleness scan failed");
    await saveRunState(opts.sql, {
      ...runState,
      status: "failed",
      errorMessage,
    });
    throw err;
  }
}
```

#### Scheduler (start/stop)

Mirror `createWikiSyncScheduler` pattern:

```typescript
let intervalHandle: ReturnType<typeof setInterval> | null = null;
let startupHandle: ReturnType<typeof setTimeout> | null = null;
let running = false;

async function doScan(): Promise<WikiStalenessScanResult> {
  if (running) {
    logger.debug("Wiki staleness scan already running, skipping");
    return { pagesScanned: 0, pagesFlagged: 0, pagesEvaluated: 0, stalePages: [], durationMs: 0, skipped: true, skipReason: "already_running" };
  }
  running = true;
  try {
    return await runScan(); // the internal scan + report delivery (plan 99-03 adds delivery)
  } finally {
    running = false;
  }
}

return {
  start() {
    const intervalMs = opts.intervalMs ?? DEFAULT_INTERVAL_MS;
    const delayMs = opts.delayMs ?? DEFAULT_STARTUP_DELAY_MS;
    logger.info({ intervalMs, delayMs }, "Wiki staleness detector starting");
    startupHandle = setTimeout(() => {
      void doScan().catch((err) => logger.error({ err }, "Initial wiki staleness scan failed"));
      intervalHandle = setInterval(() => {
        void doScan().catch((err) => logger.error({ err }, "Scheduled wiki staleness scan failed"));
      }, intervalMs);
    }, delayMs);
  },
  stop() {
    if (startupHandle) { clearTimeout(startupHandle); startupHandle = null; }
    if (intervalHandle) { clearInterval(intervalHandle); intervalHandle = null; }
    logger.info("Wiki staleness detector stopped");
  },
  runScan: doScan,
};
```

**Note on report delivery:** The Slack report delivery will be added in plan 99-03. For now, `runScan()` returns the result without posting. In 99-03, the delivery is wired in by wrapping `runScan()` to call `deliverReport()` after getting results. The cleanest approach is to have `runScan()` internally call a `deliverReport(stalePages)` helper that posts to Slack — implement this stub in 99-02 and fill it in 99-03. Alternatively, implement report delivery inline in this plan. **Choose the inline approach:** implement the full Slack delivery within `runScan()` in this file, calling `opts.slackClient.postStandaloneMessage()` and `opts.slackClient.postThreadMessage()` directly. This avoids cross-plan dependency.

**Inline report delivery inside `runScan()` (implement fully in 99-02-B):**

After computing `stalePages`, before returning:

```typescript
// Deliver report to Slack
if (stalePages.length > 0 && opts.wikiChannelId) {
  await deliverStalenessReport({
    slackClient: opts.slackClient,
    channelId: opts.wikiChannelId,
    stalePages,
    scanDate: new Date(),
    logger,
  });
}
```

Where `deliverStalenessReport` is an internal async function in the same file:

```typescript
async function deliverStalenessReport(opts: {
  slackClient: SlackClient;
  channelId: string;
  stalePages: StalePage[];
  scanDate: Date;
  logger: Logger;
}): Promise<void> {
  const { slackClient, channelId, stalePages, scanDate, logger } = opts;
  const dateStr = scanDate.toISOString().split("T")[0];

  // Split: top 5 go inline in the summary body; remainder go to thread replies only.
  const TOP_N = 5;
  const topPages = stalePages.slice(0, TOP_N);
  const remainingPages = stalePages.slice(TOP_N);

  // Build summary message body with top 5 (or all pages when <= 5) listed inline.
  const pageLines = topPages
    .map((p) => `• [${p.confidence}] <${p.pageUrl}|${p.pageTitle}> — ${p.explanation}`)
    .join("\n");

  const trailingNote =
    remainingPages.length > 0
      ? `\n_${remainingPages.length} more flagged page${remainingPages.length === 1 ? "" : "s"} in thread replies._`
      : "";

  const summaryText =
    `*Wiki Staleness Report — ${stalePages.length} page${stalePages.length === 1 ? "" : "s"} may be outdated (${dateStr})*\n` +
    pageLines +
    trailingNote;

  // Post summary message and get ts for threading
  const { ts: summaryTs } = await slackClient.postStandaloneMessage({
    channel: channelId,
    text: summaryText,
  });

  // Post one thread reply per page beyond the top 5.
  // When there are 5 or fewer stale pages total, remainingPages is empty and no thread replies are posted.
  for (const page of remainingPages) {
    const replyText = `[${page.confidence}] <${page.pageUrl}|${page.pageTitle}>\nChanged: \`${page.changedFilePath}\` (${page.commitSha.slice(0, 7)}) — ${page.explanation}`;
    try {
      await slackClient.postThreadMessage({
        channel: channelId,
        threadTs: summaryTs,
        text: replyText,
      });
    } catch (err) {
      logger.warn({ err, pageTitle: page.pageTitle }, "Failed to post thread reply for stale page (non-fatal)");
    }
  }

  logger.info({ staleCount: stalePages.length, topInSummary: topPages.length, inThreadReplies: remainingPages.length, channelId }, "Wiki staleness report delivered to Slack");
}
```

**Failure report (on scan error):** Also post failure notification to `#ai-wiki` if channel is configured. Wrap the `runScan` catch block:

```typescript
} catch (err) {
  const errorMessage = err instanceof Error ? err.message : String(err);
  logger.error({ err }, "Wiki staleness scan failed");
  await saveRunState(opts.sql, { ...runState, status: "failed", errorMessage });

  // Notify channel of failure
  if (opts.wikiChannelId) {
    try {
      await opts.slackClient.postStandaloneMessage({
        channel: opts.wikiChannelId,
        text: `Wiki Staleness Scanner failed to run: ${errorMessage.slice(0, 200)}`,
      });
    } catch (notifyErr) {
      logger.warn({ err: notifyErr }, "Failed to post staleness scan failure notification");
    }
  }
  throw err;
}
```
</task>

<task id="99-02-C" wave="3">
### Create src/knowledge/wiki-staleness-detector.test.ts

Write unit tests for the heuristic scoring logic and key pipeline behaviors.

**Test file structure:**

```typescript
import { describe, it, expect, vi, beforeEach } from "vitest";
// Import heuristic score helper (export it from wiki-staleness-detector.ts for testing)
```

**Export the heuristic helper for testing:** Add `export` keyword to `heuristicScore` in `wiki-staleness-detector.ts`:
```typescript
export function heuristicScore(...) { ... }
```

**Tests to write:**

1. **heuristicScore: returns 0 when no token overlap**
   ```typescript
   it("returns 0 when no token overlap", () => {
     const score = heuristicScore(["Audio playback configuration"], ["src/video/renderer.ts"]);
     expect(score).toBe(0);
   });
   ```

2. **heuristicScore: scores positively when tokens match**
   ```typescript
   it("scores positively when file path tokens appear in chunk text", () => {
     const score = heuristicScore(["audio playback settings"], ["src/audio/player.ts"]);
     expect(score).toBeGreaterThan(0);
   });
   ```

3. **heuristicScore: short tokens (<=3 chars) are ignored**
   ```typescript
   it("ignores short tokens", () => {
     const score = heuristicScore(["api and sdk"], ["src/api/sdk.ts"]);
     expect(score).toBe(0); // "api", "sdk", "and", "src" all <= 3 chars
   });
   ```

4. **runScan: skips when wiki store is empty**
   ```typescript
   it("runScan skips when wiki store has no pages", async () => {
     const mockStore = { countBySource: vi.fn().mockResolvedValue(0) };
     const detector = createWikiStalenessDetector({
       sql: mockSql,
       wikiPageStore: mockStore as any,
       // ... other mocked deps
     });
     const result = await detector.runScan();
     expect(result.skipped).toBe(true);
     expect(result.skipReason).toBe("empty_wiki_store");
   });
   ```

5. **runScan: does not post to Slack when no stale pages found**
   ```typescript
   it("does not post to Slack when no pages are stale", async () => {
     const slackClient = { postStandaloneMessage: vi.fn(), postThreadMessage: vi.fn() };
     // ... mock empty candidates from GitHub + heuristic pass returning []
     const result = await detector.runScan();
     expect(result.stalePages).toHaveLength(0);
     expect(slackClient.postStandaloneMessage).not.toHaveBeenCalled();
   });
   ```

Create mocks for:
- `sql` (returns empty rows for runState load, succeeds on upsert)
- `wikiPageStore` (countBySource, and a raw sql mock for the chunk query)
- `githubApp` (getRepoInstallationContext returns `{ installationId: 1, defaultBranch: "master" }`, getInstallationOctokit returns mock octokit)
- `slackClient` (postStandaloneMessage, postThreadMessage)
- `taskRouter` (resolve returns a ResolvedModel with haiku model)

Use `vi.fn()` for all mocks. Keep tests focused on the pure logic (heuristic scoring) and observable outputs (skip behavior, Slack not called when no stale pages).
</task>

## Verification

```
must_haves:
  - src/knowledge/wiki-staleness-types.ts exports all required types including sortableRecencyMs on WikiPageCandidate
  - src/knowledge/wiki-staleness-detector.ts exports createWikiStalenessDetector and heuristicScore
  - runScan() returns { skipped: true, skipReason: "empty_wiki_store" } when countBySource() returns 0
  - LLM evaluation is capped at 20 pages (LLM_CAP constant)
  - Pages beyond 20-page cap are NOT included in stalePages
  - heuristicPass sorts candidates PRIMARY by sortableRecencyMs DESC, SECONDARY by heuristicScore DESC
  - WikiPageCandidate.sortableRecencyMs is set to the max commit timestamp (ms) among affectingCommitShas
  - deliverStalenessReport summary message body contains top 5 stale pages listed inline (bulleted, with confidence tier and explanation)
  - deliverStalenessReport posts thread replies ONLY for pages 6+ (remainingPages); when <= 5 stale pages total, no thread replies are posted
  - deliverStalenessReport posts standalone message + thread replies only when stalePages.length > 0
  - On scan failure, failure notification is posted to wikiChannelId
  - heuristicScore tests pass
  - bun run typecheck passes
```
