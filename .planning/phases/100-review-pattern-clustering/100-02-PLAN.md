---
phase: 100-review-pattern-clustering
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/db/migrations/013-review-clusters.sql
  - src/knowledge/cluster-store.ts
  - src/knowledge/cluster-store.test.ts
autonomous: true
requirements: [CLST-04]

must_haves:
  truths:
    - Cluster assignments and labels are persisted in PostgreSQL
    - Run state tracks last pipeline execution and status
    - Active clusters can be queried by repo
  artifacts:
    - src/db/migrations/013-review-clusters.sql
    - src/knowledge/cluster-store.ts
    - src/knowledge/cluster-store.test.ts
  key_links:
    - cluster-store.ts implements ClusterStore interface from cluster-types.ts
    - Migration creates review_clusters, review_cluster_assignments, and cluster_run_state tables
---

<objective>
Create database schema and store implementation for cluster persistence.

Purpose: Provide durable storage for clusters, assignments, labels, and pipeline run state.
Output: Migration SQL, store factory, comprehensive tests.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/phases/100-review-pattern-clustering/100-RESEARCH.md

<interfaces>
<!-- From existing codebase patterns -->

From src/db/client.ts:
```typescript
export type Sql = ReturnType<typeof postgres>;
```

From src/knowledge/cluster-types.ts (created in plan 01, but types are stable):
```typescript
export type ReviewCluster = {
  id: number; repo: string; slug: string; label: string;
  centroid: Float32Array; memberCount: number; memberCountAtLabel: number;
  filePaths: string[]; createdAt: Date; updatedAt: Date;
  labelUpdatedAt: Date; pinned: boolean; retired: boolean;
};
export type ClusterAssignment = {
  id: number; clusterId: number; reviewCommentId: number;
  probability: number; assignedAt: Date;
};
export type ClusterRunState = {
  id?: number; lastRunAt: Date | null; clustersDiscovered: number;
  commentsProcessed: number; labelsGenerated: number;
  status: "pending" | "running" | "completed" | "failed";
  errorMessage: string | null; updatedAt?: string;
};
export type ClusterStore = { /* full interface in cluster-types.ts */ };
```

From src/db/migrations/005-review-comments.sql (pattern to follow):
```sql
CREATE TABLE IF NOT EXISTS review_comments (
  id BIGSERIAL PRIMARY KEY,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  embedding vector(1024),
  -- ... other columns
  UNIQUE(repo, comment_github_id, chunk_index)
);
```

From src/knowledge/review-comment-store.ts (factory pattern to follow):
```typescript
export function createReviewCommentStore(opts: {
  sql: Sql; logger: Logger;
}): ReviewCommentStore { /* ... */ }
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create cluster database migration</name>
  <files>src/db/migrations/013-review-clusters.sql</files>
  <action>
Create migration `013-review-clusters.sql` with three tables:

**review_clusters** — stores discovered clusters:
```sql
CREATE TABLE IF NOT EXISTS review_clusters (
  id BIGSERIAL PRIMARY KEY,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  repo TEXT NOT NULL,
  slug TEXT NOT NULL,
  label TEXT NOT NULL,
  centroid vector(1024),
  member_count INTEGER NOT NULL DEFAULT 0,
  member_count_at_label INTEGER NOT NULL DEFAULT 0,
  file_paths TEXT[] NOT NULL DEFAULT '{}',
  label_updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  pinned BOOLEAN NOT NULL DEFAULT false,
  retired BOOLEAN NOT NULL DEFAULT false,
  UNIQUE(repo, slug)
);
CREATE INDEX IF NOT EXISTS idx_review_clusters_repo ON review_clusters (repo);
CREATE INDEX IF NOT EXISTS idx_review_clusters_active ON review_clusters (repo) WHERE retired = false;
```

**review_cluster_assignments** — maps comments to clusters:
```sql
CREATE TABLE IF NOT EXISTS review_cluster_assignments (
  id BIGSERIAL PRIMARY KEY,
  cluster_id BIGINT NOT NULL REFERENCES review_clusters(id) ON DELETE CASCADE,
  review_comment_id BIGINT NOT NULL REFERENCES review_comments(id) ON DELETE CASCADE,
  probability REAL NOT NULL DEFAULT 0,
  assigned_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  UNIQUE(cluster_id, review_comment_id)
);
CREATE INDEX IF NOT EXISTS idx_cluster_assignments_cluster ON review_cluster_assignments (cluster_id);
CREATE INDEX IF NOT EXISTS idx_cluster_assignments_comment ON review_cluster_assignments (review_comment_id);
```

**cluster_run_state** — singleton row tracking pipeline execution:
```sql
CREATE TABLE IF NOT EXISTS cluster_run_state (
  id INTEGER PRIMARY KEY DEFAULT 1 CHECK (id = 1),
  last_run_at TIMESTAMPTZ,
  clusters_discovered INTEGER NOT NULL DEFAULT 0,
  comments_processed INTEGER NOT NULL DEFAULT 0,
  labels_generated INTEGER NOT NULL DEFAULT 0,
  status TEXT NOT NULL DEFAULT 'pending',
  error_message TEXT,
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
);
```

Follow the existing migration pattern exactly — `CREATE TABLE IF NOT EXISTS`, named indexes with `IF NOT EXISTS`, no down migration file needed (additive-only per project constraint).
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && cat src/db/migrations/013-review-clusters.sql | head -5 && echo "Migration file exists"</automated>
  </verify>
  <done>Migration creates review_clusters, review_cluster_assignments, and cluster_run_state tables with proper indexes, foreign keys, and unique constraints.</done>
</task>

<task type="auto">
  <name>Task 2: Implement cluster store with tests</name>
  <files>src/knowledge/cluster-store.ts, src/knowledge/cluster-store.test.ts</files>
  <action>
Create `cluster-store.ts` following the `createReviewCommentStore` factory pattern.

**Factory function:**
```typescript
export function createClusterStore(opts: { sql: Sql; logger: Logger }): ClusterStore
```

**Implement all ClusterStore methods:**

1. `upsertCluster` — INSERT ... ON CONFLICT(repo, slug) DO UPDATE. Convert Float32Array centroid to pgvector string format (reuse the same `float32ArrayToVectorString` pattern from review-comment-store.ts). Store `file_paths` as TEXT[] PostgreSQL array.

2. `getActiveClusters(repo)` — SELECT WHERE repo=X AND retired=false. Parse centroid from pgvector back to Float32Array. Parse file_paths from PG text[].

3. `retireCluster(clusterId)` — UPDATE SET retired=true.

4. `updateClusterLabel(clusterId, slug, label, memberCount)` — UPDATE SET slug, label, member_count_at_label=memberCount, label_updated_at=now(). Do NOT update if pinned=true (check with WHERE pinned=false).

5. `pinClusterLabel(clusterId, slug, label)` — UPDATE SET slug, label, pinned=true.

6. `writeAssignments` — Bulk INSERT with ON CONFLICT DO NOTHING.

7. `clearAssignments(clusterId)` — DELETE FROM review_cluster_assignments WHERE cluster_id.

8. `getAssignmentsByCluster(clusterId)` — SELECT ordered by probability DESC.

9. `getRunState()` — SELECT from cluster_run_state WHERE id=1. Return default if missing.

10. `saveRunState(state)` — INSERT ON CONFLICT(id) DO UPDATE (same singleton pattern as wiki_staleness_run_state).

**For centroid conversion**, create a helper function at module level:
```typescript
function float32ArrayToVectorString(arr: Float32Array): string {
  const parts: string[] = new Array(arr.length);
  for (let i = 0; i < arr.length; i++) parts[i] = String(arr[i]);
  return `[${parts.join(",")}]`;
}
```

**Tests** in `cluster-store.test.ts`:
Follow the same mock-sql pattern used in `review-comment-store.test.ts` and `wiki-store.test.ts`. Test each method with mock SQL responses. Test the pinned=false guard on updateClusterLabel. Test upsert conflict behavior. Test getRunState returns defaults when no row exists.
  </action>
  <verify>
    <automated>cd /home/keith/src/kodiai && bun test src/knowledge/cluster-store.test.ts 2>&1 | tail -20</automated>
  </verify>
  <done>ClusterStore implementation passes all tests. All CRUD operations work. Centroid serialization/deserialization round-trips correctly. Pinned label guard works.</done>
</task>

</tasks>

<verification>
- [ ] Migration SQL is valid and follows existing patterns (additive-only)
- [ ] ClusterStore interface fully implemented
- [ ] Centroid stored as vector(1024) and retrieved as Float32Array
- [ ] file_paths stored as TEXT[] and retrieved as string[]
- [ ] Run state uses singleton pattern (id=1)
- [ ] All tests pass
</verification>

<success_criteria>
- Migration file creates 3 tables with proper constraints and indexes
- Store factory follows createXxxStore pattern
- Tests cover all store methods including edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/100-review-pattern-clustering/100-02-SUMMARY.md`
</output>
