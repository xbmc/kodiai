---
phase: 96-code-snippet-embedding
plan: 02
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/knowledge/code-snippet-chunker.ts
  - src/knowledge/code-snippet-chunker.test.ts
autonomous: true
requirements: [SNIP-01, SNIP-05]

must_haves:
  truths:
    - parseDiffHunks extracts hunks from unified diff format with correct startLine, lineCount, addedLines
    - Pure-deletion hunks are excluded (only additions/modifications)
    - Hunks with fewer than minChangedLines added lines are filtered out
    - Generated/vendored files are excluded via configurable glob patterns
    - buildEmbeddingText assembles file path + function context + PR title + added lines
    - applyHunkCap selects the largest hunks by line count when count exceeds max
  artifacts:
    - src/knowledge/code-snippet-chunker.ts
    - src/knowledge/code-snippet-chunker.test.ts
  key_links:
    - parseDiffHunks is the entry point consumed by the review handler for hunk extraction
    - buildEmbeddingText produces the text fed to the embedding provider
---

<objective>
Build the diff hunk parser and embedding text assembler using TDD.

Purpose: Parse unified diff format into embeddable hunk chunks with all filtering rules applied.
Output: Thoroughly tested chunker module with parseDiffHunks, buildEmbeddingText, applyHunkCap, and isExcludedPath.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
@/home/keith/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/execution/diff-analysis.ts
@src/knowledge/review-comment-chunker.ts

<interfaces>
<!-- From src/execution/diff-analysis.ts — language classification -->
export function classifyFileLanguage(filePath: string): string;
export const EXTENSION_LANGUAGE_MAP: Record<string, string>;

<!-- Picomatch is already a project dependency for glob matching -->
import picomatch from "picomatch";
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: TDD — Write tests for diff hunk parser</name>
  <files>src/knowledge/code-snippet-chunker.test.ts</files>
  <action>
Write comprehensive tests FIRST (RED phase). Test file: `src/knowledge/code-snippet-chunker.test.ts`.

**Test suites to create:**

1. **`parseDiffHunks`** — core hunk extraction:
   - Single hunk with additions only → extracts startLine, addedLines, functionContext
   - Multiple hunks in one file → returns array of ParsedHunk
   - Hunk with mixed additions and context lines → only + lines in addedLines
   - Pure deletion hunk (only - lines, no + lines) → excluded from output
   - Hunk header with function context `@@ -10,5 +10,7 @@ function handleClick()` → functionContext = "function handleClick()"
   - Hunk header without function context `@@ -10,5 +10,7 @@` → functionContext = ""
   - Empty diff → returns []
   - `\ No newline at end of file` marker → ignored, not counted as a line
   - `+++ b/file.ts` header line → not counted as an added line
   - Hunk with exactly minChangedLines additions → included
   - Hunk with fewer than minChangedLines additions → excluded

2. **`buildEmbeddingText`** — text assembly:
   - Includes PR title, file path, function context, and added lines
   - When functionContext is empty → omits it from prefix
   - Format: `"PR title | path/to/file.ts | functionName\nline1\nline2..."`

3. **`isExcludedPath`** — exclusion filtering:
   - `package-lock.json` matches `*.lock` → true
   - `vendor/lib/foo.ts` matches `vendor/**` → true
   - `src/main.ts` → false (not excluded)
   - `dist/bundle.js` matches `dist/**` → true
   - `generated/types.ts` matches `generated/**` → true
   - Custom patterns override defaults

4. **`applyHunkCap`** — cost bounding:
   - 5 hunks with cap of 100 → all returned
   - 150 hunks with cap of 100 → returns 100 largest by addedLines.length
   - Tie-breaking: when equal addedLines.length, preserve original order
   - Cap of 0 → returns empty (edge case)

5. **`computeContentHash`** — dedup key:
   - Same text → same hash
   - Different text → different hash
   - Returns 64-char hex string (SHA-256)

Use vitest. Import from `./code-snippet-chunker.ts`. All tests should fail initially (RED).
  </action>
  <verify>
    <automated>npx vitest run src/knowledge/code-snippet-chunker.test.ts 2>&1 | tail -5</automated>
    Tests should exist and fail (RED phase).
  </verify>
  <done>
    - Test file has 15+ test cases covering all five functions
    - Tests import from code-snippet-chunker.ts (will fail until Task 2)
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement code-snippet-chunker.ts (GREEN + REFACTOR)</name>
  <files>src/knowledge/code-snippet-chunker.ts</files>
  <action>
Implement `src/knowledge/code-snippet-chunker.ts` to make all tests pass.

**Exports:**

```typescript
import picomatch from "picomatch";
import { createHash } from "node:crypto";
import { classifyFileLanguage } from "../execution/diff-analysis.ts";

export type ParsedHunk = {
  filePath: string;
  startLine: number;
  lineCount: number;
  functionContext: string;
  addedLines: string[];
  language: string;
};

const HUNK_HEADER_RE = /^@@\s+-\d+(?:,\d+)?\s+\+(\d+)(?:,(\d+))?\s+@@\s*(.*)$/;

export function parseDiffHunks(params: {
  diffText: string;
  filePath: string;
  minChangedLines?: number;
}): ParsedHunk[];
```

Implementation details:
- Split diff text by lines, iterate looking for `@@` headers
- Track current hunk, accumulate `+` lines (excluding `+++` header lines)
- At each new `@@` or end-of-input, flush the current hunk if addedLines.length >= minChangedLines (default 3)
- Set `language` using `classifyFileLanguage(filePath)`
- Ignore `\ No newline at end of file` lines

```typescript
export function buildEmbeddingText(params: {
  hunk: ParsedHunk;
  prTitle: string;
}): string;
```
Format: `"prTitle | filePath | functionContext\naddedLine1\naddedLine2..."` (omit functionContext segment if empty)

```typescript
export function isExcludedPath(filePath: string, patterns: string[]): boolean;
```
Use `picomatch(patterns)` to test filePath.

```typescript
export function applyHunkCap(hunks: ParsedHunk[], maxHunks: number): ParsedHunk[];
```
If hunks.length <= maxHunks, return all. Otherwise sort by addedLines.length descending (stable sort), take first maxHunks.

```typescript
export function computeContentHash(text: string): string;
```
`createHash("sha256").update(text, "utf8").digest("hex")`

Run tests iteratively until all pass. Then refactor for clarity.
  </action>
  <verify>
    <automated>npx vitest run src/knowledge/code-snippet-chunker.test.ts --reporter=verbose 2>&1 | tail -30</automated>
    All tests pass (GREEN phase).
  </verify>
  <done>
    - All chunker tests pass
    - parseDiffHunks correctly extracts hunks from unified diff
    - Pure-deletion hunks excluded
    - Min changed lines filter works
    - Exclusion patterns filter generated/vendored files
    - Hunk cap selects largest hunks
    - Content hash is deterministic SHA-256
  </done>
</task>

</tasks>

<verification>
- `npx vitest run src/knowledge/code-snippet-chunker.test.ts` — all tests pass
- No external API calls needed — pure functions only
</verification>

<success_criteria>
- 15+ test cases all passing
- parseDiffHunks handles all edge cases: empty diffs, pure deletions, no-newline markers
- buildEmbeddingText produces semantic embedding text with metadata prefix
- applyHunkCap correctly bounds embedding cost
- computeContentHash produces deterministic SHA-256 hex strings
</success_criteria>

<output>
After completion, create `.planning/phases/96-code-snippet-embedding/96-02-SUMMARY.md`
</output>
