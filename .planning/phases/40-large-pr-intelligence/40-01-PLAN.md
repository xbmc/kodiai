---
phase: 40-large-pr-intelligence
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/file-risk-scorer.ts
  - src/execution/diff-analysis.ts
  - src/execution/config.ts
autonomous: true

must_haves:
  truths:
    - "Each file in a PR gets a numeric risk score from 0-100 based on composite heuristics"
    - "Risk scoring weights are configurable via .kodiai.yml largePR section"
    - "Per-file numstat data (added/removed lines) is available for risk scoring"
    - "Unknown config fields in largePR section degrade gracefully with warnings"
  artifacts:
    - path: "src/lib/file-risk-scorer.ts"
      provides: "Risk scoring types, score computation, triage function"
      exports: ["RiskWeights", "FileRiskScore", "RiskTier", "TieredFiles", "computeFileRiskScores", "triageFilesByRisk", "DEFAULT_RISK_WEIGHTS"]
    - path: "src/execution/diff-analysis.ts"
      provides: "Per-file numstat parser"
      exports: ["parseNumstatPerFile", "PerFileStats"]
    - path: "src/execution/config.ts"
      provides: "largePR config schema with section fallback"
      contains: "largePRSchema"
  key_links:
    - from: "src/lib/file-risk-scorer.ts"
      to: "src/execution/diff-analysis.ts"
      via: "imports classifyFileLanguage"
      pattern: "import.*classifyFileLanguage.*from.*diff-analysis"
    - from: "src/execution/config.ts"
      to: "src/lib/file-risk-scorer.ts"
      via: "config types align with RiskWeights"
      pattern: "largePR"
---

<objective>
Foundation: risk scoring engine, per-file numstat parser, and largePR config schema.

Purpose: Provides the core scoring algorithm, data extraction, and configuration support that all subsequent plans depend on. The risk scorer takes per-file numstat data, path risk signals, file categories, and language data to produce sorted risk scores. The config schema makes thresholds and weights configurable per-repo.

Output: `src/lib/file-risk-scorer.ts` (scoring engine + triage), new export in `src/execution/diff-analysis.ts` (per-file numstat), and extended `src/execution/config.ts` (largePR schema + section fallback).
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/40-large-pr-intelligence/40-RESEARCH.md
@src/execution/diff-analysis.ts
@src/execution/config.ts
@src/lib/file-risk-scorer.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Per-file numstat parser and risk scoring engine</name>
  <files>src/lib/file-risk-scorer.ts, src/execution/diff-analysis.ts</files>
  <action>
1. In `src/execution/diff-analysis.ts`, add a new exported function `parseNumstatPerFile()` and type `PerFileStats`:
   - `export type PerFileStats = Map<string, { added: number; removed: number }>;`
   - Function parses the same numstat line format as existing `parseNumstat()` (`<added>\t<removed>\t<filepath>`)
   - Handle binary files (`-\t-\tpath`) by treating as 0 lines changed
   - Handle paths with tabs by joining remaining parts
   - Do NOT modify the existing `parseNumstat()` function

2. Create `src/lib/file-risk-scorer.ts` with:
   - Types: `RiskWeights`, `FileRiskScore`, `RiskTier` ("full" | "abbreviated" | "mention-only"), `TieredFiles`
   - `DEFAULT_RISK_WEIGHTS` constant: `{ linesChanged: 0.30, pathRisk: 0.30, fileCategory: 0.20, languageRisk: 0.10, fileExtension: 0.10 }`
   - `PATH_RISK_PATTERNS` array: auth/secrets patterns (1.0), migration/schema (0.8), infrastructure (0.5), dependency manifests (0.4). Use picomatch for matching (already in project).
   - `CATEGORY_RISK` map: source=1.0, infra=0.7, config=0.4, test=0.2, docs=0.1
   - `LANGUAGE_RISK` map: C/C++=1.0, PHP/Go=0.6, Rust/Java=0.5, JS=0.5, TS/Python/Ruby=0.4, Unknown=0.3
   - `isExecutableExtension()` helper: returns true for code file extensions (ts, tsx, js, py, go, rs, java, etc.)
   - `computeFileRiskScores()` function:
     - Takes files[], perFileStats, filesByCategory, weights (RiskWeights)
     - Normalizes linesChanged using log scale: `min(1.0, log10(totalLines + 1) / log10(maxLinesInPR + 1))`
     - Path risk: highest matching PATH_RISK_PATTERNS weight via picomatch
     - Category: reverse lookup from filesByCategory map, default "source"
     - Language: from classifyFileLanguage() in diff-analysis.ts
     - Extension: isExecutableExtension ? 1.0 : 0.3
     - Normalize weights at runtime: divide each weight by sum (handles user configs that don't sum to 1.0)
     - Weighted composite score scaled to 0-100
     - Returns sorted descending by score
   - `triageFilesByRisk()` function:
     - Takes riskScores[], fileThreshold, fullReviewCount, abbreviatedCount
     - If totalFiles <= threshold: all files "full", isLargePR=false
     - If totalFiles > threshold: slice into full/abbreviated/mentionOnly tiers from sorted scores
     - Returns TieredFiles with full[], abbreviated[], mentionOnly[], totalFiles, threshold, isLargePR

Import `classifyFileLanguage` from `../execution/diff-analysis.ts` and `picomatch` from "picomatch".
  </action>
  <verify>
Run `bunx tsc --noEmit` to confirm no type errors. Verify exports: `bun -e "import { computeFileRiskScores, triageFilesByRisk, DEFAULT_RISK_WEIGHTS } from './src/lib/file-risk-scorer.ts'; import { parseNumstatPerFile } from './src/execution/diff-analysis.ts'; console.log('OK')"`.
  </verify>
  <done>
`parseNumstatPerFile()` exported from diff-analysis.ts, parses per-file numstat lines into a Map. `computeFileRiskScores()` returns sorted FileRiskScore[] with 0-100 scores. `triageFilesByRisk()` splits into full/abbreviated/mentionOnly tiers. All types exported.
  </done>
</task>

<task type="auto">
  <name>Task 2: largePR config schema with section fallback parsing</name>
  <files>src/execution/config.ts</files>
  <action>
1. Add Zod schemas above `repoConfigSchema`:
   - `riskWeightsSchema`: z.object with linesChanged/pathRisk/fileCategory/languageRisk/fileExtension, all z.number().min(0).max(1), with .default() values matching DEFAULT_RISK_WEIGHTS. Add `.refine()` that checks sum is in 0.8-1.2 range -- if outside, it's still valid (just a warning, not rejection). The scoring engine normalizes at runtime.
   - `largePRSchema`: z.object with:
     - `fileThreshold`: z.number().min(10).max(1000).default(50)
     - `fullReviewCount`: z.number().min(5).max(200).default(30)
     - `abbreviatedCount`: z.number().min(0).max(200).default(20)
     - `riskWeights`: riskWeightsSchema
   - Add `.default()` providing all defaults

2. Add `largePR: largePRSchema` to `repoConfigSchema`

3. Add section fallback parsing for `largePR` in `loadRepoConfig()` (follow the exact same pattern as existing `languageRules`, `knowledge`, etc. sections):
   - Parse `obj.largePR` with `largePRSchema.safeParse()`
   - On success, use parsed value; on failure, use `largePRSchema.parse({})` and push warning
   - Include `largePR` in the final `config` object assembly

4. Update the existing section fallback's config object assembly at the bottom of `loadRepoConfig()` to include `largePR`.
  </action>
  <verify>
Run `bunx tsc --noEmit`. Run existing config tests: `bun test src/execution/config.test.ts`. Verify: `bun -e "import { loadRepoConfig } from './src/execution/config.ts'; const r = await loadRepoConfig('/tmp'); console.log(JSON.stringify(r.config.largePR))"` outputs defaults (fileThreshold:50, fullReviewCount:30, abbreviatedCount:20, weights).
  </verify>
  <done>
`largePR` section available in RepoConfig with sensible defaults. Section fallback parsing handles invalid largePR config gracefully with warnings. Existing tests still pass. Config type includes largePR with all fields typed.
  </done>
</task>

</tasks>

<verification>
- `bunx tsc --noEmit` passes
- `bun test src/execution/config.test.ts` passes (existing tests)
- `parseNumstatPerFile()` correctly parses "10\t5\tsrc/foo.ts" format
- `computeFileRiskScores()` returns scores between 0-100
- `triageFilesByRisk()` with 100 files and threshold 50 returns 30 full + 20 abbreviated + 50 mentionOnly
- `triageFilesByRisk()` with 30 files and threshold 50 returns all 30 as full, isLargePR=false
- Default config loads with largePR section populated
</verification>

<success_criteria>
Risk scoring engine computes per-file scores from composite heuristics. Triage function splits files into three tiers. Per-file numstat parser extracts line counts per file. Config schema supports largePR section with configurable thresholds and weights. All existing tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/40-large-pr-intelligence/40-01-SUMMARY.md`
</output>
