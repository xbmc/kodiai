---
phase: 46-conversational-review
plan: 03
type: execute
wave: 2
depends_on: ["46-01", "46-02"]
files_modified:
  - src/handlers/mention.ts
  - src/execution/mention-context.ts
autonomous: true

must_haves:
  truths:
    - "User can reply to a kodiai review finding with @kodiai and receive a contextual response referencing the original finding"
    - "Conversation threads are rate-limited per PR to prevent runaway token costs"
    - "Bot replies have outgoing mentions sanitized to prevent self-trigger loops"
    - "Context budget caps total conversation context characters per turn"
    - "Comment-author defense-in-depth prevents processing if trigger comment author matches app slug"
  artifacts:
    - path: "src/handlers/mention.ts"
      provides: "Conversation rate limiting, outgoing sanitization, finding lookup wiring, comment-author check"
      contains: "prConversationTurns"
    - path: "src/execution/mention-context.ts"
      provides: "Conversation-specific context budget allocation"
      contains: "contextBudgetChars"
  key_links:
    - from: "src/handlers/mention.ts"
      to: "src/execution/mention-context.ts"
      via: "Passes findingLookup callback and conversation budget to buildMentionContext"
      pattern: "findingLookup"
    - from: "src/handlers/mention.ts"
      to: "src/lib/sanitizer.ts"
      via: "Calls sanitizeOutgoingMentions on all outgoing reply bodies"
      pattern: "sanitizeOutgoingMentions"
    - from: "src/handlers/mention.ts"
      to: "src/execution/config.ts"
      via: "Reads config.mention.conversation for rate limit and budget settings"
      pattern: "config\\.mention\\.conversation"
---

<objective>
Wire conversational review into the mention handler with rate limiting, sanitization, context budget, and finding lookup integration.

Purpose: Complete the conversational review feature by connecting all the primitives from plans 01 and 02 into the live mention handler. After this plan, a user can reply to a kodiai review finding with @kodiai and receive a contextual, rate-limited, sanitized response.

Output: Fully operational conversational review in the mention handler.
</objective>

<execution_context>
@/home/keith/.claude/get-shit-done/workflows/execute-plan.md
@/home/keith/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/46-conversational-review/46-RESEARCH.md
@.planning/phases/46-conversational-review/46-01-SUMMARY.md
@.planning/phases/46-conversational-review/46-02-SUMMARY.md

@src/handlers/mention.ts
@src/execution/mention-context.ts
@src/execution/mention-prompt.ts
@src/lib/sanitizer.ts
@src/execution/config.ts
@src/knowledge/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire rate limiting, sanitization, and comment-author defense into mention handler</name>
  <files>
    src/handlers/mention.ts
  </files>
  <action>
**Import additions:**
- Add `sanitizeOutgoingMentions` import from `../lib/sanitizer.ts`

**Comment-author defense-in-depth (early in handleMention, after normalization):**
- After the fast filter (line ~172), add a check: if `mention.commentAuthor.toLowerCase()` matches `appSlug.toLowerCase()` or ends with `[bot]`, return early. This prevents the bot from processing its own comments even if the bot filter fails. Log at debug level: "Skipping mention from self (comment-author defense)".

**Per-PR conversation rate limiter (in-memory Map, same pattern as lastWriteAt):**
- Add a new Map at the handler level: `const prConversationTurns = new Map<string, number>();`
- Add a pruning function `pruneConversationTurns(now: number)` following the same pattern as `pruneRateLimiter`: 24h TTL, 10k max entries.
- Inside the job callback, after config is loaded:
  - Read `config.mention.conversation.maxTurnsPerPr`.
  - Build rate-limit key: `${mention.owner}/${mention.repo}#${mention.prNumber ?? mention.issueNumber}`.
  - If the trigger is a reply to a review comment (`mention.inReplyToId` is defined):
    - Check current turn count: `const turns = prConversationTurns.get(key) ?? 0;`
    - If `turns >= maxTurnsPerPr`, post a rate-limit message via `postMentionReply`:
      ```
      Conversation limit reached (${maxTurnsPerPr} turns per PR).
      Start a new thread or open a new issue for further questions.
      ```
      Then return.
  - After successful execution (after the executor.execute call), if `mention.inReplyToId` is defined, increment: `prConversationTurns.set(key, (prConversationTurns.get(key) ?? 0) + 1);`
  - Call `pruneConversationTurns(Date.now())` before the rate limit check to keep the map bounded.

**Outgoing mention sanitization:**
- Modify `postMentionReply` and `postMentionError` to sanitize the reply body before posting:
  ```typescript
  const sanitizedBody = sanitizeOutgoingMentions(replyBody, possibleHandles);
  ```
  Then use `sanitizedBody` instead of `replyBody` in the API calls.
- Also sanitize the fallback reply body (the "no published output" fallback at line ~1072).
- This is defense-in-depth: even if the LLM generates `@kodiai` in its response, the sanitizer strips it before posting.

**Wire findingLookup callback to buildMentionContext:**
- After loading config, build the findingLookup callback:
  ```typescript
  const findingLookup = deps.knowledgeStore?.getFindingByCommentId
    ? (repo: string, commentId: number) => deps.knowledgeStore!.getFindingByCommentId!({ repo, commentId })
    : undefined;
  ```
- Pass `findingLookup` to `buildMentionContext`:
  ```typescript
  mentionContext = await buildMentionContext(octokit, mention, { findingLookup });
  ```

**Wire findingContext to buildMentionPrompt:**
- When `mention.inReplyToId` is defined and `findingLookup` is available, call `findingLookup` to get the finding. If non-null, pass it as `findingContext` to `buildMentionPrompt`.
  ```typescript
  const findingContext = mention.inReplyToId && findingLookup
    ? findingLookup(`${mention.owner}/${mention.repo}`, mention.inReplyToId) ?? undefined
    : undefined;
  ```
  Then add `findingContext` to the buildMentionPrompt call.
  </action>
  <verify>
Run `bun test` -- all tests pass. TypeScript compiles without errors. Review the handler code to confirm: (1) all outgoing replies pass through sanitizeOutgoingMentions, (2) conversation rate limit check is in place, (3) comment-author defense is present, (4) findingLookup is wired through.
  </verify>
  <done>
Mention handler has: (1) comment-author defense-in-depth, (2) per-PR conversation turn counter with configurable max, (3) outgoing mention sanitization on all reply paths, (4) findingLookup wired to buildMentionContext and findingContext wired to buildMentionPrompt.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add conversation-specific context budget to buildMentionContext</name>
  <files>
    src/execution/mention-context.ts
  </files>
  <action>
**Context budget for thread history:**
- Add `maxThreadChars?: number` to `BuildMentionContextOptions`. Default: `undefined` (falls back to `maxConversationChars`).
- In the thread context section (added in plan 01), use `options.maxThreadChars ?? maxConversationChars` as the thread-specific budget.
- Recent turns (last 2-3) get full inclusion up to `maxCommentChars` per comment. Older turns get truncated to first 200 characters using `truncateDeterministic(body, 200)`.
- The split point: if there are more than 3 thread comments (excluding the trigger), the oldest `N - 3` get the truncated treatment.
- Thread budget is separate from the issue comment conversation budget. Both draw from the same `maxConversationChars` pool unless `maxThreadChars` is explicitly set.

**Wire in mention handler:**
- The mention handler (from Task 1) passes `maxThreadChars: config.mention.conversation.contextBudgetChars` to buildMentionContext options. Update the buildMentionContext call in the mention handler accordingly.

**Budget enforcement summary:**
- Issue comments: up to `maxConversationChars` (existing behavior, unchanged)
- Thread comments: up to `maxThreadChars` (new, defaults to `maxConversationChars`, configurable via `mention.conversation.contextBudgetChars`)
- Per-comment: up to `maxCommentChars` (existing, unchanged)
- Old thread turns (beyond most recent 3): truncated to 200 chars each
  </action>
  <verify>
Run `bun test src/execution/mention-context.test.ts` -- all tests pass. Run `bun test` -- no regressions. Verify that a long thread (>3 comments) truncates older turns to 200 chars while keeping recent turns full-length.
  </verify>
  <done>
Thread context uses a dedicated character budget (configurable via mention.conversation.contextBudgetChars). Recent turns get full allocation. Older turns are truncated to 200 chars. Budget enforcement prevents context window explosion on long conversation threads.
  </done>
</task>

</tasks>

<verification>
1. `bun test` -- all tests pass with no regressions
2. End-to-end behavior: when a pr_review_comment with in_reply_to_id triggers a mention, the handler loads finding context, builds thread-aware context with budget, sanitizes outgoing reply, and respects rate limits
3. Defense-in-depth confirmed: comment-author check + outgoing sanitization + rate limiter all active
4. TypeScript compiles without errors
</verification>

<success_criteria>
- User can reply to a kodiai review finding with @kodiai and the bot responds with finding-specific context
- Conversation turns are rate-limited per PR (configurable, default 10)
- All outgoing bot replies have @kodiai/@claude stripped
- Thread context is capped by contextBudgetChars (configurable, default 8000)
- Old thread turns are truncated while recent turns get full context
- Comment-author defense prevents self-processing
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/46-conversational-review/46-03-SUMMARY.md`
</output>
